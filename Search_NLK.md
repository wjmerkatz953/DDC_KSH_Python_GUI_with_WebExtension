# -*- coding: utf-8 -*-
# íŒŒì¼ëª…: Search_NLK.py
# Version: v6.0.0 (Refactored)
# ìˆ˜ì •ì¼ì‹œ: 2025-09-20 KST
# ì„¤ëª…: NLK OpenAPI í†µí•© ê²€ìƒ‰ ëª¨ë“ˆ. Search_UPenn.py ìŠ¤íƒ€ì¼ì˜ ê³„ì¸µì  êµ¬ì¡°ë¡œ ë¦¬íŒ©í† ë§ë¨.

import requests
import xml.etree.ElementTree as ET
import re
import time
import urllib.parse
from concurrent.futures import ThreadPoolExecutor, as_completed
from api_clients import clean_text

# ==============================================================================
# ðŸŽ¯ 1. ì„¤ì • ë° ì˜ˆì™¸ í´ëž˜ìŠ¤ (ì¤‘ì•™ ì§‘ì¤‘ ê´€ë¦¬)
# ==============================================================================

NLK_CONFIG = {
    "BASE_URL": "https://www.nl.go.kr/NL/search/openApi/search.do",
    "MARC_DOWNLOAD_URL": "https://www.nl.go.kr/NL/marcDownload.do?downData={view_key},AH1",
    "MODS_DOWNLOAD_URL": "https://www.nl.go.kr/NL/search/mods_view.do?contentsId={view_key}",
    "DEFAULT_PAGE_SIZE": 30,
    "TIMEOUT": 20,
    "MARC_MODS_MAX_WORKERS": 8,
    "MARC_MODS_TIMEOUT": 10,
    "USER_AGENT": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36",
}

_nlk_cache = {}


class NLKSearchError(Exception):
    """NLK ê²€ìƒ‰ ê´€ë ¨ ì»¤ìŠ¤í…€ ì˜ˆì™¸"""

    pass


# ==============================================================================
# ðŸŽ¯ 2. ë©”ì¸ ì§„ìž…ì  í•¨ìˆ˜
# ==============================================================================


def search_nlk_catalog(
    title_query=None,
    author_query=None,
    isbn_query=None,
    ddc_query=None,
    year_query=None,  # í˜„ìž¬ NLK APIì—ì„œ ë¯¸ì‚¬ìš©, í–¥í›„ í™•ìž¥ì„±ì„ ìœ„í•´ ìœ ì§€
    app_instance=None,
    db_manager=None,
):
    """NLK í†µí•© ê²€ìƒ‰ - ë‹¨ì¼ ì§„ìž…ì """
    try:
        # âœ¨ year_queryë„ ê²€ì¦ì— í¬í•¨
        if not any([title_query, author_query, isbn_query, ddc_query, year_query]):
            raise NLKSearchError("ê²€ìƒ‰ì–´ê°€ í•˜ë‚˜ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")

        api_key = get_nlk_api_key(db_manager)
        if not api_key:
            raise NLKSearchError("NLK API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # API íŒŒë¼ë¯¸í„° êµ¬ì„±
        # âœ¨ year_queryë„ íŒŒë¼ë¯¸í„° ë¹Œë”ì— ì „ë‹¬
        api_params = _build_api_params(
            title_query, author_query, isbn_query, ddc_query, year_query, api_key
        )

        # API í˜¸ì¶œ ë° ê¸°ë³¸ íŒŒì‹±
        raw_results = _route_and_parse_search(api_params, app_instance)

        # MARC/MODS ë°ì´í„°ë¡œ í›„ì²˜ë¦¬
        processed_results = _post_process_with_marc_mods(raw_results, app_instance)

        if app_instance:
            app_instance.log_message(
                f"ì •ë³´: NLK ê²€ìƒ‰ ì™„ë£Œ. ìµœì¢… {len(processed_results)}ê±´ ê²°ê³¼ ë°˜í™˜.",
                level="INFO",
            )

        return processed_results

    except Exception as e:
        _handle_nlk_error(e, app_instance, context="ë©”ì¸ ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤")
        return []


# ==============================================================================
# ðŸŽ¯ 3. API íŒŒë¼ë¯¸í„° ë¹Œë” ë° ë¼ìš°í„°
# ==============================================================================


def _build_api_params(
    title_query, author_query, isbn_query, ddc_query, year_query, api_key
):
    """ê²€ìƒ‰ ì¡°ê±´ì— ë”°ë¼ API íŒŒë¼ë¯¸í„°ë¥¼ ë™ì ìœ¼ë¡œ êµ¬ì„±"""
    params = {
        "key": api_key,
        "detailSearch": "true",
        "pageNum": 1,
        "pageSize": NLK_CONFIG["DEFAULT_PAGE_SIZE"],
    }

    # -------------------
    # âœ¨ FIX: DDC ê²€ìƒ‰ì„ ìœ„í•œ íŠ¹ë³„ íŒŒë¼ë¯¸í„° ìš°ì„  ì²˜ë¦¬
    if ddc_query:
        params["gu2"] = "ddc"
        params["guCode2"] = ddc_query
    # -------------------

    # OpenAPI ê°€ì´ë“œ v2.6ì— ë”°ë¥¸ ë³µí•© ê²€ìƒ‰ í•„ë“œ êµ¬ì„±
    fields = []
    if title_query:
        fields.append(("title", title_query))
    if author_query:
        fields.append(("author", author_query))
    if year_query:
        fields.append(("pub_year", year_query))  # âœ¨ ì—°ë„ í•„ë“œ ì¶”ê°€
    # ðŸž BUG FIX: DDCëŠ” ìœ„ì—ì„œ íŠ¹ë³„ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œ ì œê±°

    if isbn_query:
        params["isbnOp"] = "isbn"
        params["isbnCode"] = isbn_query

    # ë‚¨ì€ ì¼ë°˜ í•„ë“œë“¤ì„ f, v íŒŒë¼ë¯¸í„°ë¡œ êµ¬ì„±
    if fields:
        # DDCê°€ ì´ë¯¸ ì²˜ë¦¬ëœ ê²½ìš°ë¥¼ ê³ ë ¤í•˜ì—¬ and ë¡œì§ì„ ìœ ì—°í•˜ê²Œ ì¡°ì •
        start_index = 2 if ddc_query else 1
        for i, (field_name, value) in enumerate(fields, start_index):
            params[f"f{i}"] = field_name
            params[f"v{i}"] = value
            if i > 1:
                params[f"and{i-1}"] = "AND"

    return params


def _route_and_parse_search(api_params, app_instance):
    """APIë¥¼ í˜¸ì¶œí•˜ê³  ê¸°ë³¸ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ëŠ” ë¼ìš°í„°"""
    if app_instance:
        app_instance.log_message(
            f"ì •ë³´: NLK API ìš”ì²­ ì‹œìž‘. Params: {api_params}", level="INFO"
        )

    response = _call_nlk_api(api_params, app_instance)
    return _parse_nlk_xml_response(response.text, app_instance)


# ==============================================================================
# ðŸŽ¯ 4. API í˜¸ì¶œ ë° íŒŒì‹± ê³„ì¸µ
# ==============================================================================


def _call_nlk_api(api_params, app_instance):
    """í†µí•© NLK API í˜¸ì¶œ í•¨ìˆ˜"""
    try:
        response = requests.get(
            NLK_CONFIG["BASE_URL"],
            params=api_params,
            headers={"User-Agent": NLK_CONFIG["USER_AGENT"]},
            timeout=NLK_CONFIG["TIMEOUT"],
        )
        response.raise_for_status()
        return response
    except requests.exceptions.RequestException as e:
        raise NLKSearchError(f"API ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹¤íŒ¨: {e}")


def _parse_nlk_xml_response(xml_text, app_instance):
    """NLK APIì˜ XML ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ê¸°ë³¸ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
    try:
        root = ET.fromstring(xml_text)
        result_element = root.find("result")
        if result_element is None:
            if app_instance:
                app_instance.log_message(
                    "ì •ë³´: NLK ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (result ì—˜ë¦¬ë¨¼íŠ¸ ì—†ìŒ)", level="INFO"
                )
            return []

        results = []
        for item_element in result_element.findall("item"):
            results.append(_map_nlk_api_item_to_dict(item_element))

        if app_instance:
            app_instance.log_message(
                f"ì •ë³´: NLK API ê¸°ë³¸ íŒŒì‹± ì™„ë£Œ. {len(results)}ê±´", level="INFO"
            )
        return results
    except ET.ParseError as e:
        raise NLKSearchError(f"XML íŒŒì‹± ì‹¤íŒ¨: {e}")


def _map_nlk_api_item_to_dict(item):
    """XML item ì—˜ë¦¬ë¨¼íŠ¸ë¥¼ í‘œì¤€ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
    detail_link = clean_text(item.findtext("detail_link", ""))
    if detail_link.startswith("/"):
        detail_link = "https://www.nl.go.kr" + detail_link

    return {
        "ì œëª©": clean_text(item.findtext("title_info", "")),
        "ì €ìž": clean_text(item.findtext("author_info", "")),
        "ì¶œíŒì‚¬": clean_text(item.findtext("pub_info", "")),
        "ì—°ë„": clean_text(item.findtext("pub_year_info", "")),
        "ISBN": clean_text(item.findtext("isbn", "")),
        "ìƒì„¸ ë§í¬": detail_link,
        "KDC": clean_text(item.findtext("class_no", "")),
        "viewKey": extract_nlk_view_key_from_detail_link(detail_link),
        # ì•„ëž˜ í•„ë“œë“¤ì€ í›„ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì±„ì›Œì§
        "082": "",
        "650 í•„ë“œ": "",
    }


# ==============================================================================
# ðŸŽ¯ 5. ìƒì„¸ ì •ë³´ í›„ì²˜ë¦¬ ê³„ì¸µ (MARC/MODS)
# ==============================================================================


def _post_process_with_marc_mods(raw_results, app_instance):
    """MARC/MODS ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ê°€ì ¸ì™€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ê°•"""
    if not raw_results:
        return []

    view_keys = [res["viewKey"] for res in raw_results if res.get("viewKey")]
    if not view_keys:
        return raw_results

    marc_data_map = _batch_fetch_marc_mods_data(view_keys, app_instance)

    for result in raw_results:
        vk = result.get("viewKey")
        if vk in marc_data_map:
            marc_info = marc_data_map[vk]
            result["082"] = marc_info.get("ddc") or result.get("082", "")
            if marc_info.get("kdc"):
                result["KDC"] = marc_info.get("kdc")
            if marc_info.get("kac"):
                result["ì €ìž"] = "; ".join(marc_info["kac"])
            if marc_info.get("ksh"):
                result["650 í•„ë“œ"] = "; ".join(marc_info["ksh"])

    return raw_results


def _batch_fetch_marc_mods_data(view_keys, app_instance):
    """MARC/MODS ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  íŒŒì‹±"""
    if not view_keys:
        return {}
    if app_instance:
        app_instance.log_message(
            f"ì •ë³´: {len(view_keys)}ê°œ ë ˆì½”ë“œ MARC/MODS ìƒì„¸ ì •ë³´ ë³‘ë ¬ ìš”ì²­ ì‹œìž‘...",
            level="INFO",
        )

    start_time = time.time()
    results = {}

    keys_to_fetch = []
    for vk in view_keys:
        if vk in _nlk_cache:
            results[vk] = _nlk_cache[vk]
        else:
            keys_to_fetch.append(vk)

    if not keys_to_fetch:
        return results

    with ThreadPoolExecutor(
        max_workers=NLK_CONFIG["MARC_MODS_MAX_WORKERS"]
    ) as executor:
        future_to_vk = {
            executor.submit(_fetch_and_parse_single_marc_mod, vk, app_instance): vk
            for vk in keys_to_fetch
        }

        for future in as_completed(future_to_vk):
            vk = future_to_vk[future]
            try:
                data = future.result()
                results[vk] = data
                _nlk_cache[vk] = data  # ìºì‹œì— ì €ìž¥
            except Exception as e:
                _handle_nlk_error(e, app_instance, f"MARC/MODS ì²˜ë¦¬ ({vk})")
                results[vk] = {"ddc": None, "kdc": None, "kac": [], "ksh": []}

    elapsed = time.time() - start_time
    if app_instance:
        app_instance.log_message(
            f"ì •ë³´: MARC/MODS ìƒì„¸ ì •ë³´ ì²˜ë¦¬ ì™„ë£Œ. {len(keys_to_fetch)}ê±´ in {elapsed:.2f}ì´ˆ",
            level="INFO",
        )

    return results


def _fetch_and_parse_single_marc_mod(view_key, app_instance):
    """ë‹¨ì¼ viewKeyì— ëŒ€í•œ MARC ë˜ëŠ” MODS ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ íŒŒì‹±"""
    if view_key.startswith("CNTS-"):
        return _fetch_mods_data_single(view_key, app_instance)
    else:
        return _fetch_marc_data_single(view_key, app_instance)


# ==============================================================================
# ðŸŽ¯ 6. ìœ í‹¸ë¦¬í‹° ë° ë ˆê±°ì‹œ íŒŒì‹± í•¨ìˆ˜ (ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ìœ ì§€)
# ==============================================================================


def get_nlk_api_key(db_manager):
    return db_manager.get_setting("nlk_api_key") if db_manager else None


def extract_nlk_view_key_from_detail_link(detail_link):
    if not detail_link:
        return None
    match = re.search(
        r"viewKey=([A-Za-z]+-[A-Za-z0-9]+|[A-Za-z]+[0-9]+|\d+)", detail_link
    )
    return match.group(1) if match else None


def _handle_nlk_error(error, app_instance, context=""):
    error_msg = f"NLK {context} ì˜¤ë¥˜: {error}"
    if app_instance:
        app_instance.log_message(error_msg, level="ERROR")


# --- ì•„ëž˜ í•¨ìˆ˜ë“¤ì€ ë©”ë¥´ì¹´ì¸ ë‹˜ê»˜ì„œ ì™„ì„±í•˜ì‹  ë¡œì§ìœ¼ë¡œ, ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤. ---


def _fetch_marc_data_single(view_key, app_instance):
    marc_url = NLK_CONFIG["MARC_DOWNLOAD_URL"].format(view_key=view_key)
    try:
        with requests.Session() as session:
            response = session.get(
                marc_url,
                headers={"User-Agent": NLK_CONFIG["USER_AGENT"]},
                timeout=NLK_CONFIG["MARC_MODS_TIMEOUT"],
            )
        if response.status_code == 200:
            response.encoding = "utf-8"
            marc_content = response.text
            if "Ã¬" in marc_content or "Ã«" in marc_content:
                marc_content = response.content.decode("utf-8", errors="ignore")
            ddc, kdc, kac, ksh = _extract_marc_data(marc_content, app_instance)
            return {"ddc": ddc, "kdc": kdc, "kac": kac, "ksh": ksh}
        return {"ddc": None, "kdc": None, "kac": [], "ksh": []}
    except Exception as e:
        raise NLKSearchError(f"MARC ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({view_key}): {e}")


def _fetch_mods_data_single(view_key, app_instance):
    mods_url = NLK_CONFIG["MODS_DOWNLOAD_URL"].format(view_key=view_key)
    try:
        with requests.Session() as session:
            response = session.get(
                mods_url,
                headers={"User-Agent": NLK_CONFIG["USER_AGENT"]},
                timeout=NLK_CONFIG["MARC_MODS_TIMEOUT"],
            )
        if response.status_code == 200 and response.content:
            ddc, kdc, kac, ksh = _parse_mods_xml_content(response.content, app_instance)
            return {"ddc": ddc, "kdc": kdc, "kac": kac, "ksh": ksh}
        return {"ddc": None, "kdc": None, "kac": [], "ksh": []}
    except Exception as e:
        raise NLKSearchError(f"MODS ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({view_key}): {e}")


def _extract_marc_data(marc_content, app_instance):
    if not marc_content:
        return None, None, [], []
    ddc_code, kdc_code, kac_authors, ksh_subjects = None, None, [], []
    try:
        ddc_matches = re.findall(r"\x1fa(\d+(?:\.\d+)?)\x1f2\d{2}", marc_content)
        if ddc_matches:
            ddc_code = ddc_matches[0]
        cut_match = re.search(r"\x1fc\d{2} cm", marc_content)
        clean_marc = marc_content[cut_match.end() :] if cut_match else marc_content
        ksh_big_matches = re.findall(r"8\x1fa(.*?)\x1f0KSH(\d{10})", clean_marc)
        processed_ksh = set()
        for raw_subject, ksh_digits in ksh_big_matches:
            ksh_code = f"KSH{ksh_digits}"
            clean_subject = re.sub(
                r"[\x00-\x1f\x7f-\x9f]|\s+", " ", raw_subject
            ).strip()
            if (
                len(clean_subject) >= 2
                and not clean_subject.isdigit()
                and ksh_code not in processed_ksh
            ):
                ksh_subjects.append(f"â–¼a{clean_subject}â–¼0{ksh_code}â–²")
                processed_ksh.add(ksh_code)
        kac_pattern = r"1\s*(?:\x1f6.+?)?\x1fa([^\x1e]+?)\x1f0(KAC[A-Z\d]+)"
        processed_kac = set()
        matches = re.findall(kac_pattern, clean_marc)
        for author_part, kac_code in matches:
            clean_name = author_part.split("\x1f")[0].rstrip(",").strip()
            if (
                clean_name
                and len(clean_name) >= 2
                and kac_code not in processed_kac
                and any(c.isalpha() or "\uac00" <= c <= "\ud7af" for c in clean_name)
            ):
                kac_authors.append(f"{clean_name} {kac_code}")
                processed_kac.add(kac_code)
        if not kac_authors:
            kac_authors = ["KAC ì €ìžëª… ì—†ìŒ"]
        if not ksh_subjects:
            ksh_subjects = ["KSH ì£¼ì œëª… ì—†ìŒ"]
        return ddc_code, kdc_code, kac_authors, ksh_subjects
    except Exception as e:
        if app_instance:
            app_instance.log_message(f"âš ï¸ MARC íŒŒì‹± ì˜¤ë¥˜: {e}", level="WARNING")
        return None, None, ["KAC ì €ìžëª… ì—†ìŒ (ì˜¤ë¥˜)"], ["KSH ì£¼ì œëª… ì—†ìŒ (ì˜¤ë¥˜)"]


def _parse_mods_xml_content(xml_content, app_instance):
    if not xml_content:
        return None, None, [], []
    ddc_code, kdc_code, kac_authors, ksh_subjects = None, None, [], []
    try:
        root = ET.fromstring(xml_content)
        namespaces = {"mods": "http://www.loc.gov/mods/v3"}
        classification_elements = root.findall(
            './/mods:classification[@authority="DDC"]', namespaces
        )
        for classification in classification_elements:
            if classification.text and classification.text.strip():
                ddc_code = classification.text.strip()
                break
        kdc_elements = root.findall(
            './/mods:classification[@authority="KDC"]', namespaces
        )
        for classification in kdc_elements:
            if classification.text and classification.text.strip():
                kdc_code = classification.text.strip()
                break
        name_elements = root.findall('.//mods:name[@type="personal"]', namespaces)
        processed_kac = set()
        for name_element in name_elements:
            kac_id = name_element.get("ID", "")
            if kac_id and kac_id.startswith("KAC"):
                name_part = name_element.find("mods:namePart", namespaces)
                if name_part is not None and name_part.text:
                    author_name = name_part.text.strip()
                    if author_name and kac_id not in processed_kac:
                        kac_authors.append(f"{author_name} {kac_id}")
                        processed_kac.add(kac_id)
        subject_elements = root.findall(".//mods:subject", namespaces)
        processed_ksh = set()
        for subject_element in subject_elements:
            ksh_id = subject_element.get("ID", "").strip()
            if ksh_id and ksh_id.startswith("KSH"):
                topic_element = subject_element.find("mods:topic", namespaces)
                if topic_element is not None and topic_element.text:
                    subject_text = topic_element.text.strip()
                    if subject_text and ksh_id not in processed_ksh:
                        ksh_subjects.append(f"â–¼a{subject_text}â–¼0{ksh_id}â–²")
                        processed_ksh.add(ksh_id)
        return ddc_code, kdc_code, kac_authors, ksh_subjects
    except Exception as e:
        if app_instance:
            app_instance.log_message(f"âš ï¸ MODS XML íŒŒì‹± ì˜¤ë¥˜: {e}", level="WARNING")
        return (
            None,
            None,
            ["KAC ì €ìžëª… ì—†ìŒ (MODS ì˜¤ë¥˜)"],
            ["KSH ì£¼ì œëª… ì—†ìŒ (MODS ì˜¤ë¥˜)"],
        )
