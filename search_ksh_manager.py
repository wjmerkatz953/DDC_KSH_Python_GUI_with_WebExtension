# íŒŒì¼ëª…: search_ksh_manager.py
# ì„¤ëª…: KSH(í•œêµ­ì£¼ì œëª…í‘œëª©) ê²€ìƒ‰ ì „ìš© ëª¨ë“ˆ

import pandas as pd
import re
import time
import logging
from typing import List
from database_manager import DatabaseManager
from search_common_manager import SearchCommonManager

logger = logging.getLogger("qt_main_app.database_manager")


class SearchKshManager(SearchCommonManager):
    """
    KSHíƒ­ ì „ìš© ê²€ìƒ‰ í´ë˜ìŠ¤
    - KSH ê°œë… ê²€ìƒ‰
    - í•œê¸€ ì£¼ì œëª… ê²€ìƒ‰
    - í†µí•© ê²€ìƒ‰
    - ê°œë… ê´€ê³„ì–´ ì¡°íšŒ
    """

    def _format_korean_search_results(self, df, search_term=None):
        if df.empty:
            return df
        try:
            # ksh_labeled â†’ ë§ˆí¬ì—…ìœ¼ë¡œ ë³€í™˜
            df["ksh_labeled"] = df.apply(
                lambda row: self._format_ksh_labeled_to_markup(
                    row.get("ksh_labeled", ""), row.get("ksh", "")
                ),
                axis=1,
            )
            # í‘œì‹œìš©
            df["matched"] = df["ksh_korean"]

            # âœ… [ì‹ ê·œ ì¶”ê°€] DDC ë ˆì´ë¸” ë° ì¶œí˜„ ì¹´ìš´íŠ¸ ë§¤í•‘
            if "ddc" in df.columns:
                # DDC ë ˆì´ë¸” ë§¤í•‘
                unique_ddcs = df["ddc"].dropna().unique().tolist()
                if unique_ddcs:
                    ddc_label_map = self.get_all_ddc_labels_bulk(unique_ddcs)
                    df["ddc_label"] = df["ddc"].map(ddc_label_map).fillna("")
                else:
                    df["ddc_label"] = ""

                # DDC ì¶œí˜„ ì¹´ìš´íŠ¸ ê³„ì‚°
                ddc_counts = df["ddc"].value_counts()
                df["ddc_count"] = df["ddc"].map(ddc_counts).fillna(0).astype(int)

            # âœ… [ì‹ ê·œ ì¶”ê°€] ê²€ìƒ‰ì–´ ê¸°ë°˜ ì •ë ¬ ë¡œì§
            print(
                f"ğŸ” [DEBUG] _format_korean_search_results called with search_term: '{search_term}'"
            )
            if search_term:
                print(
                    f"ğŸ” [DEBUG] ì •ë ¬ ë¡œì§ ì‹œì‘ - ê²€ìƒ‰ì–´: '{search_term}', ê²°ê³¼: {len(df)}ê°œ"
                )
                # DDC ë¹ˆë„ ê³„ì‚° (ê° DDCê°€ mapping_dataì—ì„œ ëª‡ ë²ˆ ë‚˜íƒ€ë‚˜ëŠ”ì§€)
                ddc_counts = df["ddc"].value_counts().to_dict()
                df["ddc_frequency"] = df["ddc"].map(ddc_counts).fillna(0)
                # print(f"ğŸ” [DEBUG] DDC ë¹ˆë„: {ddc_counts}")

                # âœ… [ë””ë²„ê·¸] ìƒ˜í”Œ ksh_korean í™•ì¸
                print(f"ğŸ” [DEBUG] ìƒ˜í”Œ ksh_korean (ì²« 3ê°œ):")
                for idx, ksh in enumerate(df["ksh_korean"].head(3), 1):
                    print(f"  {idx}. {ksh}")

                # ë§¤ì¹­ ìš°ì„ ìˆœìœ„ ê³„ì‚° í•¨ìˆ˜
                def _calculate_match_priority(row):
                    ksh_korean = str(row.get("ksh_korean", "")).lower()
                    search_lower = search_term.strip().replace(" ", "").lower()
                    ddc_freq = row.get("ddc_frequency", 0)

                    # ksh_koreanì—ì„œ ê° ì£¼ì œëª… ì¶”ì¶œ (ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ë¶„ë¦¬)
                    subjects = [s.strip() for s in ksh_korean.split(";") if s.strip()]

                    for subject in subjects:
                        # ê´„í˜¸ ì œê±°í•œ ìˆœìˆ˜ ì£¼ì œëª…
                        pure_subject = re.sub(r"[\(\[].*?[\)\]]", "", subject).strip()

                        # 1ìˆœìœ„: ìˆœìˆ˜ ì£¼ì œëª…ì—ì„œ ì™„ì „ ë§¤ì¹­
                        if pure_subject == search_lower:
                            return (1, -ddc_freq, row.get("publication_year", 0))

                    for subject in subjects:
                        pure_subject = re.sub(r"[\(\[].*?[\)\]]", "", subject).strip()

                        # 2ìˆœìœ„: ìˆœìˆ˜ ì£¼ì œëª…ì—ì„œ ë¶€ë¶„ ë§¤ì¹­
                        if search_lower in pure_subject:
                            return (2, -ddc_freq, row.get("publication_year", 0))

                    # 3ìˆœìœ„: ê´„í˜¸ ì•ˆ ë§¤ì¹­
                    for subject in subjects:
                        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì¶”ì¶œ
                        paren_content = re.findall(r"\(([^\)]+)\)", subject)
                        bracket_content = re.findall(r"\[([^\]]+)\]", subject)

                        all_content = " ".join(paren_content + bracket_content).lower()
                        if search_lower in all_content:
                            return (3, -ddc_freq, row.get("publication_year", 0))

                    # 4ìˆœìœ„: ê¸°íƒ€
                    return (4, -ddc_freq, row.get("publication_year", 0))

                # ìš°ì„ ìˆœìœ„ ê³„ì‚°
                df["_sort_priority"] = df.apply(_calculate_match_priority, axis=1)

                # âœ… [ë””ë²„ê·¸] ìš°ì„ ìˆœìœ„ ë¶„í¬ í™•ì¸
                priority_dist = (
                    df["_sort_priority"]
                    .apply(lambda x: x[0])
                    .value_counts()
                    .sort_index()
                )
                print(f"ğŸ” [DEBUG] ìš°ì„ ìˆœìœ„ ë¶„í¬: {dict(priority_dist)}")

                # ì •ë ¬: ìš°ì„ ìˆœìœ„ â†’ DDC ë¹ˆë„ â†’ ë°œí–‰ì—°ë„
                df = df.sort_values("_sort_priority").drop(
                    ["_sort_priority", "ddc_frequency"], axis=1
                )
                # âœ… ì •ë ¬ í›„ ìƒìœ„ 200ê°œë§Œ ë°˜í™˜
                df = df.head(200)
                print(f"ğŸ” [DEBUG] ì •ë ¬ ì™„ë£Œ - ìƒìœ„ {len(df)}ê°œ ë°˜í™˜")
            else:
                # ê²€ìƒ‰ì–´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ëŒ€ë¡œ ë°œí–‰ì—°ë„ ì—­ìˆœ
                df["pub_year_numeric"] = pd.to_numeric(
                    df["publication_year"], errors="coerce"
                ).fillna(0)
                df = df.sort_values("pub_year_numeric", ascending=False).drop(
                    "pub_year_numeric", axis=1
                )
                # âœ… ìƒìœ„ 200ê°œë§Œ ë°˜í™˜
                df = df.head(200)

            # âŒ (ì‚­ì œ ê¸ˆì§€) if "ksh" in df.columns: df.drop(...)

            return df.fillna("")
        except Exception as e:
            print(f"ê²½ê³ : í•œêµ­ì–´ ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜: {e}")
            return df

    # ğŸ’ ë§ˆìŠ¤í„° ê²€ìƒ‰ í•¨ìˆ˜

    def _format_ksh_column_optimized(
        self, ksh_codes_str: str, ksh_korean: str = "", ksh_labeled: str = ""
    ) -> str:
        """
        ğŸ”§ í¬ë§·íŒ… í•¨ìˆ˜ë„ ì •ê·œí™”ëœ ë°ì´í„°ì— ë§ì¶° ìˆ˜ì •
        """
        if not ksh_codes_str or pd.isna(ksh_codes_str):
            return ""

        import re

        # ksh_labeledì—ì„œ ë¼ë²¨ ì¶”ì¶œ
        label_map = {}
        if ksh_labeled and str(ksh_labeled).lower() != "nan":
            for segment in str(ksh_labeled).split(";"):
                seg = segment.strip().replace("\u00a0", " ")
                # ì´ë¯¸ í¬ë§·ëœ ê²½ìš° íŒŒì‹±
                m_fmt = re.match(r"^â–¼a(.+?)â–¼0(?i:(ksh)\d+)â–²$", seg)
                if m_fmt:
                    label_map[m_fmt.group(2).upper()] = m_fmt.group(1).strip()
                    continue
                # ì¼ë°˜ì ì¸ "ë¼ë²¨ - KSH123" íŒ¨í„´
                m = re.match(r"^(?P<label>.+?)\s*[-â€“â€”]\s*(?P<code>(?i:ksh)\d+)$", seg)
                if m:
                    label_map[m.group("code").upper()] = m.group("label").strip()

        # KSH ì½”ë“œ í† í°í™”
        codes = [t for t in re.split(r"[,\s]+", str(ksh_codes_str)) if t.strip()]
        out = []

        for raw in codes:
            code = raw.strip().upper()
            if not code.startswith("KSH"):
                out.append(raw)
                continue

            # ë¼ë²¨ ë§¤í•‘ ìš°ì„ ìˆœìœ„
            if code in label_map:
                label = label_map[code]
                out.append(f"â–¼a{label}â–¼0{code}â–²")
                continue

            # ksh_korean ì‚¬ìš© (ì •ê·œí™”ëœ ìƒíƒœ)
            if ksh_korean and str(ksh_korean).lower() != "nan":
                # ì£¼ì˜: ksh_koreanì€ ì´ì œ ê³µë°±ì´ ì œê±°ëœ ìƒíƒœ
                first_ko = str(ksh_korean).split(";")[0].strip()
                if first_ko:
                    out.append(f"â–¼a{first_ko}â–¼0{code}â–²")
                    continue

            # ìµœì¢… í´ë°±: ì½”ë“œë§Œ
            out.append(code)

        return ", ".join(out)

    def _format_ksh_display(self, concept_id: str, label: str) -> str:
        """KSH í‘œì‹œ í˜•ì‹: â–¼a{label}â–¼0{KSH_code}â–²"""
        ksh_code = self._strip_namespace(concept_id)
        return f"â–¼a{label}â–¼0{ksh_code}â–²"

    def _format_ksh_labeled_to_markup(
        self, ksh_labeled: str, ksh_fallback: str = ""
    ) -> str:
        if not ksh_labeled or str(ksh_labeled).lower() == "nan":
            return ksh_fallback or ""

        # ì´ë¯¸ ë§ˆí¬ì—…ì´ë©´ ê·¸ëŒ€ë¡œ
        if (
            "â–¼a" in str(ksh_labeled)
            and "â–¼0" in str(ksh_labeled)
            and "â–²" in str(ksh_labeled)
        ):
            return str(ksh_labeled)

        segments = str(ksh_labeled).split(";")
        formatted = []
        for seg in segments:
            s = seg.strip()
            if not s:
                continue
            m = re.match(r"^(?P<label>.+?)\s*[-â€“â€”]\s*(?P<code>(?i:ksh)\d+)$", s)
            if m:
                label = m.group("label").strip()
                code = m.group("code").upper()
                formatted.append(f"â–¼a{label}â–¼0{code}â–²")
            else:
                formatted.append(s)
        return "; ".join(formatted) if formatted else (ksh_fallback or "")

    def _get_broader_for_concept(self, conn, concept_id: str) -> list:
        """ê°œë…ì˜ ìƒìœ„ì–´ë“¤ì„ KSH í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        cursor = conn.cursor()

        # broader ê´€ê³„ ì¡°íšŒ
        cursor.execute(
            "SELECT target FROM uri_props WHERE concept_id=? AND prop='broader'",
            (concept_id,),
        )
        broader_ids = [row[0] for row in cursor.fetchall() if row and row[0]]

        # narrowerì˜ ì—­ê´€ê³„ë„ í™•ì¸
        cursor.execute(
            "SELECT concept_id FROM uri_props WHERE target=? AND prop='narrower'",
            (concept_id,),
        )
        inverse_broader = [row[0] for row in cursor.fetchall() if row and row[0]]

        # ì¤‘ë³µ ì œê±°
        all_broader = list(set(broader_ids + inverse_broader))

        broader_terms = []
        for broader_id in all_broader:
            broader_label = self._get_pref_label(conn, broader_id)
            if broader_label:
                broader_terms.append(
                    self._format_ksh_display(broader_id, broader_label)
                )

        return broader_terms

    def _get_narrower_for_concept(self, conn, concept_id: str) -> list:
        """ê°œë…ì˜ í•˜ìœ„ì–´ë“¤ì„ KSH í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        cursor = conn.cursor()

        # narrower ê´€ê³„ ì¡°íšŒ
        cursor.execute(
            "SELECT target FROM uri_props WHERE concept_id=? AND prop='narrower'",
            (concept_id,),
        )
        narrower_ids = [row[0] for row in cursor.fetchall() if row and row[0]]

        # broaderì˜ ì—­ê´€ê³„ë„ í™•ì¸
        cursor.execute(
            "SELECT concept_id FROM uri_props WHERE target=? AND prop='broader'",
            (concept_id,),
        )
        inverse_narrower = [row[0] for row in cursor.fetchall() if row and row[0]]

        # ì¤‘ë³µ ì œê±°
        all_narrower = list(set(narrower_ids + inverse_narrower))

        narrower_terms = []
        for narrower_id in all_narrower:
            narrower_label = self._get_pref_label(conn, narrower_id)
            if narrower_label:
                narrower_terms.append(
                    self._format_ksh_display(narrower_id, narrower_label)
                )

        return narrower_terms

    def _get_related_for_concept(self, conn, concept_id: str) -> list:
        """ê°œë…ì˜ ê´€ë ¨ì–´ë“¤ì„ KSH í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        cursor = conn.cursor()
        cursor.execute(
            "SELECT target FROM uri_props WHERE concept_id=? AND prop='related'",
            (concept_id,),
        )
        related_ids = [row[0] for row in cursor.fetchall() if row and row[0]]

        related_terms = []
        for related_id in related_ids:
            related_label = self._get_pref_label(conn, related_id)
            if related_label:
                related_terms.append(
                    self._format_ksh_display(related_id, related_label)
                )

        # -------------------
        # í•­ëª© ìˆ˜ ì œí•œ ì œê±° - ëª¨ë“  ê´€ë ¨ì–´ë¥¼ í‘œì‹œ
        return related_terms  # ğŸ¯ [:20] ì œê±°í•˜ì—¬ ì „ì²´ í‘œì‹œ
        # -------------------

    def _get_synonyms_for_concept(
        self, conn, concept_id: str, exclude_term: str = None
    ) -> list:
        """ë™ì˜ì–´ ì¡°íšŒ + ì–¸ì–´íƒœê·¸ ì¤‘ë³µ ì œê±° ì ìš©"""
        cursor = conn.cursor()
        cursor.execute(
            "SELECT value FROM literal_props WHERE concept_id=? AND prop='altLabel'",
            (concept_id,),
        )
        synonyms = [row[0] for row in cursor.fetchall() if row and row[0]]

        if exclude_term:
            synonyms = [s for s in synonyms if s != exclude_term]

        # ğŸ¯ ì–¸ì–´íƒœê·¸ ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        return self.dedup_lang_variants(synonyms)

    def _search_by_korean_subject(self, korean_terms):
        """
        kdc_to_dd DBì—ì„œ í•œêµ­ì–´ ì£¼ì œëª…ìœ¼ë¡œ ì§ì ‘ ê²€ìƒ‰
        âœ… [ì„±ëŠ¥ ê°œì„ ] 2ë‹¨ê³„ ê²€ìƒ‰(CTE)ì„ í†µí•´ FTS5ì™€ SQL ì •ë ¬ì˜ ì¥ì ì„ ëª¨ë‘ í™œìš©í•©ë‹ˆë‹¤.
        """
        conn = None
        try:
            conn = self.db_manager._get_mapping_connection()
            cursor = conn.cursor()
            cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='table' AND name='mapping_data_fts'"
            )
            use_fts = cursor.fetchone() is not None

            if not use_fts:
                logger.warning(
                    "âš ï¸ FTS5 í…Œì´ë¸”ì´ ì—†ì–´ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤. (LIKE ê²€ìƒ‰ ë¹„í™œì„±í™”)"
                )
                return pd.DataFrame()

            # ğŸš€ FTS5 + SQL ìµœì í™” ì¿¼ë¦¬
            search_term = korean_terms[0] if korean_terms else ""
            if not search_term:
                return pd.DataFrame()

            term_clean = search_term.strip().replace(" ", "")

            # FTS5ìš© ì¿¼ë¦¬ (ë‹¨ì¼ ê²€ìƒ‰ì–´ ê¸°ì¤€)
            fts_query = f'ksh_korean:("{term_clean}" OR {term_clean}*)'

            # -------------------
            # âœ… [í•µì‹¬ ì„±ëŠ¥ ê°œì„ ] WITH ì ˆ(CTE)ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ë‹¨ê³„ë¥¼ ëª…í™•íˆ ë¶„ë¦¬
            # 1ë‹¨ê³„: FTS5ì—ì„œ rank ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 10,000ê°œì˜ í›„ë³´ rowidë¥¼ ë¹ ë¥´ê²Œ ì¶”ì¶œ
            # 2ë‹¨ê³„: ì¶”ì¶œëœ 10,000ê°œì˜ rowidë§Œ ê°€ì§€ê³  ì‹¤ì œ í…Œì´ë¸”ê³¼ JOINí•˜ì—¬ ì •ë°€ ì •ë ¬
            query = """
            WITH TopFtsResults AS (
                SELECT rowid
                FROM mapping_data_fts
                WHERE mapping_data_fts MATCH ?
                ORDER BY rank -- FTS5ì˜ ë‚´ì¥ ê´€ë ¨ë„ ì ìˆ˜(rank)ë¡œ 1ì°¨ ì •ë ¬
                LIMIT 10000
            )
            SELECT
                m.identifier, m.kdc, m.ddc, m.ksh, m.kdc_edition, m.ddc_edition,
                m.publication_year, m.title, m.data_type, m.source_file,
                m.ksh_labeled, m.ksh_korean,
                (LENGTH(m.ksh) - LENGTH(REPLACE(m.ksh, 'KSH', ''))) / 3 as ksh_count,
                CASE
                    WHEN m.ksh_korean = ? THEN 0 -- 1ìˆœìœ„: ì™„ì „ ì¼ì¹˜
                    WHEN m.ksh_korean LIKE ? THEN 1 -- 2ìˆœìœ„: ë§¨ ì•ì— ì¼ì¹˜
                    ELSE 2 -- 3ìˆœìœ„: ê·¸ ì™¸ FTS ë§¤ì¹­
                END as match_priority
            FROM TopFtsResults tfr -- ì „ì²´ í…Œì´ë¸”ì´ ì•„ë‹Œ 10,000ê±´ì˜ í›„ë³´ í…Œì´ë¸”
            JOIN mapping_data m ON tfr.rowid = m.rowid
            ORDER BY
                match_priority ASC,      -- 1. ì •í™•ë„ ìˆœ
                publication_year DESC,   -- 2. ë°œí–‰ë…„ë„ ìµœì‹ ìˆœ
                ksh_count DESC           -- 3. KSH ê°œìˆ˜ ë§ì€ ìˆœ
            """

            # SQL íŒŒë¼ë¯¸í„°: FTSì¿¼ë¦¬, CASEìš© íŒŒë¼ë¯¸í„° 2ê°œ
            params = (fts_query, term_clean, f"{term_clean};%")
            df_result = pd.read_sql_query(query, conn, params=params)
            # -------------------

            if not df_result.empty:
                logger.info(
                    f"ğŸ¯ [SQL ìµœì í™”] ì„œì§€ DB ê²€ìƒ‰ ì™„ë£Œ: {len(df_result)}ê°œ ê²°ê³¼ë§Œ ê°€ì ¸ì™€ í›„ì²˜ë¦¬ ì‹œì‘"
                )
                formatted_result = self._format_korean_search_results(
                    df_result, search_term
                )
                return formatted_result
            else:
                return pd.DataFrame()

        except Exception as e:
            print(f"ì˜¤ë¥˜: í•œêµ­ì–´ ì£¼ì œëª… ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return pd.DataFrame()
        finally:
            if conn:
                conn.close()

    def _search_by_ksh_code(self, ksh_codes):
        conn = self.db_manager._get_mapping_connection()
        try:
            query_parts = ["ksh LIKE ?"] * len(ksh_codes)
            # âœ… [ì„±ëŠ¥ ê°œì„ ] í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¡°íšŒ
            query = f"""
                SELECT
                    identifier,
                    kdc,
                    ddc,
                    ksh,
                    ksh_korean,
                    ksh_labeled,
                    kdc_edition,
                    ddc_edition,
                    publication_year,
                    title,
                    source_file
                FROM mapping_data
                WHERE {' OR '.join(query_parts)}
            """
            params = [f"%{code}%" for code in ksh_codes]
            df = pd.read_sql_query(query, conn, params=params)

            # ğŸš€ ì„±ëŠ¥ ê°œì„ : í–‰ ë‹¨ìœ„ë¡œ ìµœì í™”ëœ í¬ë§·íŒ… ì ìš©
            if not df.empty and "ksh" in df.columns:
                df["ksh"] = df.apply(
                    lambda row: self._format_ksh_column_optimized(
                        row.get("ksh", ""),
                        row.get("ksh_korean", ""),
                        row.get("ksh_labeled", ""),
                    ),
                    axis=1,
                )

            return df.fillna("")
        finally:
            if conn:
                conn.close()

    def get_concept_relations(self, keyword):
        """
        íŠ¹ì • í‚¤ì›Œë“œì˜ ìƒ/í•˜ìœ„ì–´, ê´€ë ¨ì–´ ì •ë³´ ë°˜í™˜
        ì‹¤ì œ Concept DB êµ¬ì¡°ì— ë§ì¶° êµ¬í˜„
        """
        conn = None
        try:
            conn = self.db_manager._get_concepts_connection()
            cursor = conn.cursor()

            # ì •ê·œí™”ëœ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
            normalized_keyword = keyword.strip().lower().replace(" ", "")

            # 1. í‚¤ì›Œë“œë¡œ concept_idë“¤ ì°¾ê¸°
            search_query = """
            SELECT DISTINCT concept_id, value, prop
            FROM literal_props
            WHERE concept_id LIKE 'nlk:KSH%'
            AND concept_id NOT LIKE 'nls:%'
            AND (value_normalized LIKE ? OR value LIKE ?)
            AND prop IN ('prefLabel', 'label', 'altLabel')
            LIMIT 10
            """

            cursor.execute(search_query, (f"%{normalized_keyword}%", f"%{keyword}%"))
            concept_results = cursor.fetchall()

            relations = {
                "broader": [],  # ìƒìœ„ì–´
                "narrower": [],  # í•˜ìœ„ì–´
                "related": [],  # ê´€ë ¨ì–´
                "synonyms": [],  # ë™ì˜ì–´/ì´í˜•ì–´
            }

            # 2. ê° concept_idì— ëŒ€í•´ ê´€ê³„ ì •ë³´ ì¡°íšŒ
            for concept_row in concept_results:
                concept_id = concept_row[0]

                # object_props í…Œì´ë¸”ì—ì„œ ê´€ê³„ ì¡°íšŒ
                relations_query = """
                SELECT op.prop, op.object_id
                FROM object_props op
                WHERE op.subject_id = ?
                AND op.prop IN ('broader', 'narrower', 'related')
                """

                cursor.execute(relations_query, (concept_id,))
                relation_results = cursor.fetchall()

                # ê´€ë ¨ ê°œë…ë“¤ì˜ ë¼ë²¨ ì¡°íšŒ
                for rel_row in relation_results:
                    relation_type = rel_row[0]  # broader, narrower, related
                    related_concept_id = rel_row[1]

                    # ê´€ë ¨ ê°œë…ì˜ preferredLabel ì¡°íšŒ
                    label_query = """
                    SELECT value FROM literal_props
                    WHERE concept_id = ? AND prop = 'prefLabel'
                    LIMIT 1
                    """

                    cursor.execute(label_query, (related_concept_id,))
                    label_result = cursor.fetchone()

                    if label_result and relation_type in relations:
                        related_term = label_result[0]
                        if (
                            related_term
                            and related_term not in relations[relation_type]
                        ):
                            relations[relation_type].append(related_term)

            # ê° ê´€ê³„ íƒ€ì…ë³„ë¡œ ìµœëŒ€ 3ê°œë¡œ ì œí•œ
            for relation_type in relations:
                relations[relation_type] = relations[relation_type][:3]

            return relations

        except Exception as e:
            print(f"ì˜¤ë¥˜: Concept DB ê´€ê³„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"broader": [], "narrower": [], "related": [], "synonyms": []}
        finally:
            if conn:
                conn.close()

    def _build_fts5_query(self, processed_term: str) -> str:
        """
        FTS5 ê²€ìƒ‰ ì¿¼ë¦¬ ë¬¸ìì—´ ìƒì„±

        Args:
            processed_term: ì „ì²˜ë¦¬ëœ ê²€ìƒ‰ì–´

        Returns:
            FTS5 MATCH ì¿¼ë¦¬ ë¬¸ìì—´
        """
        normalized_term = processed_term.replace(" ", "")

        if "," in processed_term:
            # ë‹¤ì¤‘ ê²€ìƒ‰ì–´: "í•œêµ­" OR "ê²½ì œ" OR ...
            terms = [
                term.strip().replace(" ", "")
                for term in processed_term.split(",")
                if term.strip()
            ]

            fts_terms = []
            for t in terms:
                sanitized_t = re.sub(r"[^\w]", "", t)
                if sanitized_t:
                    fts_terms.append(f'"{sanitized_t}" OR {sanitized_t}*')

            return " OR ".join(fts_terms)
        else:
            # ë‹¨ì¼ ê²€ìƒ‰ì–´: "í•œêµ­" OR í•œêµ­*
            sanitized_term = re.sub(r"[^\w]", "", normalized_term)
            if sanitized_term:
                return f'"{sanitized_term}" OR {sanitized_term}*'
            else:
                return ""

    def _execute_fts5_search(
        self, cursor, fts_query: str, main_category: str = None, limit: int = None
    ) -> list:
        """
        FTS5 ì „ë¬¸ ê²€ìƒ‰ ì‹¤í–‰

        Args:
            cursor: ë°ì´í„°ë² ì´ìŠ¤ ì»¤ì„œ
            fts_query: FTS5 MATCH ì¿¼ë¦¬ ë¬¸ìì—´ (Noneì´ë©´ ì¹´í…Œê³ ë¦¬ ì „ìš© ê²€ìƒ‰)
            main_category: ì£¼ì œ ì¹´í…Œê³ ë¦¬ í•„í„°
            limit: ê²°ê³¼ ê°œìˆ˜ ì œí•œ

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [(concept_id, matched_value), ...]
        """
        # âœ… ì¹´í…Œê³ ë¦¬ ì „ìš© ê²€ìƒ‰ (fts_queryê°€ Noneì¸ ê²½ìš°)
        if fts_query is None:
            base_query = """
            SELECT DISTINCT
                lp.concept_id,
                lp.value as matched_value,
                lp.prop,
                CASE lp.prop WHEN 'prefLabel' THEN 1 WHEN 'label' THEN 2 WHEN 'altLabel' THEN 3 ELSE 4 END as prop_priority
            FROM literal_props lp
            LEFT JOIN category_mapping cm ON lp.concept_id = cm.concept_id
            WHERE lp.concept_id LIKE 'nlk:KSH%'
            AND lp.concept_id NOT LIKE 'nls:%'
            AND lp.prop IN ('prefLabel', 'label', 'altLabel')
            """
            params = []

            # ì¹´í…Œê³ ë¦¬ í•„í„° (í•„ìˆ˜)
            if main_category and main_category != "ì „ì²´":
                base_query += " AND cm.main_category = ?"
                params.append(main_category)
        else:
            # ì¼ë°˜ FTS5 ê²€ìƒ‰
            base_query = """
            SELECT DISTINCT
                lp.concept_id,
                lp.value as matched_value,
                lp.prop,
                CASE lp.prop WHEN 'prefLabel' THEN 1 WHEN 'label' THEN 2 WHEN 'altLabel' THEN 3 ELSE 4 END as prop_priority
            FROM literal_props_fts fts
            JOIN literal_props lp ON fts.rowid = lp.rowid
            LEFT JOIN category_mapping cm ON lp.concept_id = cm.concept_id
            WHERE lp.concept_id LIKE 'nlk:KSH%'
            AND lp.concept_id NOT LIKE 'nls:%'
            AND lp.prop IN ('prefLabel', 'label', 'altLabel')
            AND fts.value_normalized MATCH ?
            """
            params = [fts_query]

            # ì£¼ì œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
            if main_category and main_category != "ì „ì²´":
                base_query += " AND cm.main_category = ?"
                params.append(main_category)

        # ORDER BY (ì¹´í…Œê³ ë¦¬ ì „ìš©ì€ fts.rank ì—†ìŒ)
        if fts_query is None:
            base_query += """
            ORDER BY
                prop_priority ASC,
                LENGTH(lp.value) ASC,
                lp.value ASC
            """
        else:
            base_query += """
            ORDER BY
                fts.rank ASC,
                prop_priority ASC,
                LENGTH(lp.value) ASC,
                lp.value ASC
            """

        # WITH + WINDOW FUNCTIONìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        optimized_query = f"""
        WITH RankedResults AS (
            {base_query}
        )
        SELECT DISTINCT
            concept_id,
            FIRST_VALUE(matched_value) OVER (
                PARTITION BY concept_id
                ORDER BY prop_priority ASC, LENGTH(matched_value) ASC
            ) as matched_value
        FROM RankedResults
        """

        cursor.execute(optimized_query, params)
        all_results = cursor.fetchall()

        # Pythonì—ì„œ LIMIT ì ìš©
        return all_results[:limit] if limit else all_results

    def _fetch_concept_details(self, cursor, concept_ids: list) -> list:
        """
        ê°œë…ë“¤ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ë°°ì¹˜)

        Args:
            cursor: ë°ì´í„°ë² ì´ìŠ¤ ì»¤ì„œ
            concept_ids: ì¡°íšŒí•  concept_id ë¦¬ìŠ¤íŠ¸

        Returns:
            ìƒì„¸ ì •ë³´ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        placeholders = ",".join("?" for _ in concept_ids)
        detail_query = f"""
        SELECT
            c.concept_id,
            (
                SELECT value FROM literal_props
                WHERE concept_id = c.concept_id AND prop IN ('prefLabel', 'label')
                ORDER BY CASE prop WHEN 'prefLabel' THEN 1 ELSE 2 END
                LIMIT 1
            ) as pref_label,
            cm.main_category,
            dm.ddc_classification,
            km.kdc_like_classification
        FROM concepts c
        LEFT JOIN category_mapping cm ON c.concept_id = cm.concept_id
        LEFT JOIN ddc_mapping dm ON c.concept_id = dm.concept_id
        LEFT JOIN kdc_mapping km ON c.concept_id = km.concept_id
        WHERE c.concept_id IN ({placeholders})
        """
        cursor.execute(detail_query, concept_ids)
        return cursor.fetchall()

    def _fetch_concept_relations(self, conn, concept_ids: list) -> dict:
        """
        ê°œë…ë“¤ì˜ ê´€ê³„ì–´ ì¡°íšŒ (broader, narrower, related, synonyms)

        Args:
            conn: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            concept_ids: ì¡°íšŒí•  concept_id ë¦¬ìŠ¤íŠ¸

        Returns:
            {concept_id: {'broader': [...], 'narrower': [...], 'related': [...], 'synonyms': [...]}}
        """
        relations = {}

        for cid in concept_ids:
            relations[cid] = {
                "broader": self._get_broader_for_concept(conn, cid),
                "narrower": self._get_narrower_for_concept(conn, cid),
                "related": self._get_related_for_concept(conn, cid),
                "synonyms": self._get_synonyms_for_concept(conn, cid),
            }

        return relations

    def _calculate_match_priority(self, matched_value: str, search_term: str) -> tuple:
        """
        ë§¤ì¹­ ìš°ì„ ìˆœìœ„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        ë©”ë¥´ì¹´ì¸ ë‹˜ ìš”êµ¬ì‚¬í•­:
        1ìˆœìœ„: ì™„ë²½ ë§¤ì¹­(ì „ë°©ë§¤ì¹­ + ê¸€ì ìˆ˜ê¹Œì§€ ì™„ë²½ ë§¤ì¹­)
        2ìˆœìœ„: ì „ë°© ë§¤ì¹­ì¸ë° ê¸€ììˆ˜ê°€ ì§§ì€ ê²ƒ
        3ìˆœìœ„: ì „ë°© ë§¤ì¹­ì´ ì•„ë‹ˆë©´ì„œ ê¸€ììˆ˜ê°€ ì§§ì€ ê²ƒ
        4ìˆœìœ„: ì›ê´„í˜¸ ì•ˆ ë§¤ì¹­

        Returns:
            tuple: (priority, length, alphabetical_sort_key)
        """
        if not matched_value or not search_term:
            return (5, 9999, matched_value or "")

        # í•œê¸€ ì—¬ë¶€ ê²€ì‚¬
        has_korean = bool(re.search(r"[\uac00-\ud7a3]", search_term))

        # ìˆœìˆ˜ ì£¼ì œëª… ì¶”ì¶œ (ê´„í˜¸/ê°ê´„í˜¸ ì œê±°)
        pure_subject = self._get_clean_subject_for_sorting(matched_value)

        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì¶”ì¶œ
        parentheses_content = ""
        brackets_content = ""

        paren_match = re.search(r"\(([^)]*)\)", matched_value)
        if paren_match:
            parentheses_content = paren_match.group(1)

        bracket_match = re.search(r"\[([^\]]*)\]", matched_value)
        if bracket_match:
            brackets_content = bracket_match.group(1)

        # í•œê¸€ê³¼ ì˜ì–´ì— ë”°ë¥¸ ë‹¤ë¥¸ ì •ê·œí™” ë°©ì‹ ì ìš©
        if has_korean:
            # í•œê¸€ ê²€ìƒ‰: ë‹¨ìˆ˜í™” ì—†ì´ ê³µë°± ì œê±° + ì†Œë¬¸ìë§Œ
            norm_search = re.sub(r"\s+", "", search_term.lower())
            norm_pure = re.sub(r"\s+", "", pure_subject.lower())
            norm_paren = re.sub(r"\s+", "", parentheses_content.lower())
            norm_bracket = re.sub(r"\s+", "", brackets_content.lower())
        else:
            # ì˜ì–´ ê²€ìƒ‰: ê¸°ì¡´ _norm_for_compare ë¡œì§ ì‚¬ìš© (ë‹¨ìˆ˜í™” í¬í•¨)
            def _norm_for_compare_en(s: str) -> str:
                if not s:
                    return ""
                base = self._get_clean_subject_for_sorting(str(s))
                base = re.sub(r"\s+", "", base).lower()
                try:
                    base = inflection.singularize(base)
                except Exception:
                    pass
                return base

            norm_search = _norm_for_compare_en(search_term)
            norm_pure = _norm_for_compare_en(pure_subject)
            norm_paren = _norm_for_compare_en(parentheses_content)
            norm_bracket = _norm_for_compare_en(brackets_content)

        # 1ìˆœìœ„: ì™„ë²½ ë§¤ì¹­ (ìˆœìˆ˜ ì£¼ì œëª…ì—ì„œ ì „ë°©ë§¤ì¹­ + ê¸¸ì´ ì¼ì¹˜)
        if norm_pure.startswith(norm_search) and len(norm_pure) == len(norm_search):
            return (1, len(pure_subject), pure_subject.lower())

        # 2ìˆœìœ„: ì „ë°© ë§¤ì¹­ì´ë©´ì„œ ìˆœìˆ˜ ì£¼ì œëª…ì´ ì§§ì€ ê²ƒ
        if norm_pure.startswith(norm_search):
            return (2, len(pure_subject), pure_subject.lower())

        # 3ìˆœìœ„: ìˆœìˆ˜ ì£¼ì œëª…ì— í¬í•¨ë˜ì§€ë§Œ ì „ë°©ë§¤ì¹­ì´ ì•„ë‹Œ ê²ƒ (ì§§ì€ ìˆœ)
        if norm_search in norm_pure:
            return (3, len(pure_subject), pure_subject.lower())

        # 4ìˆœìœ„: ì›ê´„í˜¸ ì•ˆì—ì„œ ë§¤ì¹­
        if norm_search in norm_paren or norm_paren.startswith(norm_search):
            return (4, len(matched_value), matched_value.lower())

        # 5ìˆœìœ„: ê°ê´„í˜¸ ì•ˆì—ì„œ ë§¤ì¹­
        if norm_search in norm_bracket or norm_bracket.startswith(norm_search):
            return (4, len(matched_value), matched_value.lower())

        # 6ìˆœìœ„: ê¸°íƒ€ (ë§¤ì¹­ë˜ì§€ ì•ŠìŒ)
        return (5, len(matched_value), matched_value.lower())

    def _build_concepts_dataframe(
        self,
        detail_results: list,
        relations: dict,
        concept_match_map: dict,
        processed_term: str,
    ) -> pd.DataFrame:
        """
        ê°œë… ê²€ìƒ‰ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ êµ¬ì„±

        Args:
            detail_results: ìƒì„¸ ì •ë³´ ê²°ê³¼
            relations: ê´€ê³„ì–´ ë”•ì…”ë„ˆë¦¬
            concept_match_map: {concept_id: matched_value}
            processed_term: ì „ì²˜ë¦¬ëœ ê²€ìƒ‰ì–´

        Returns:
            ì •ë ¬ ë° í¬ë§·íŒ…ëœ DataFrame
        """
        # ë‹¤ì¤‘ ê²€ìƒ‰ì–´ ì²˜ë¦¬
        first_search_term = (
            processed_term.split(",")[0].strip()
            if "," in processed_term
            else processed_term
        )

        # ê²°ê³¼ êµ¬ì„±
        rows = []
        for row in detail_results:
            concept_id = row["concept_id"]
            matched_value = concept_match_map.get(concept_id, "")

            # ìš°ì„ ìˆœìœ„ ê³„ì‚°
            priority = self._calculate_match_priority(matched_value, first_search_term)

            # KSH ë§ˆí¬ì—… í˜•ì‹ìœ¼ë¡œ ì£¼ì œëª… ìƒì„±: â–¼a{label}â–¼0{KSH_code}â–²
            pref_label = row["pref_label"] or matched_value
            subject_with_code = self._format_ksh_display(concept_id, pref_label)

            rows.append(
                {
                    "concept_id": concept_id,
                    "subject": subject_with_code,
                    "main_category": row["main_category"] or "",
                    "classification_ddc": row["ddc_classification"] or "",
                    "classification_kdc_like": row["kdc_like_classification"] or "",
                    "matched": matched_value,
                    "related": "; ".join(
                        relations.get(concept_id, {}).get("related", [])
                    ),
                    "broader": "; ".join(
                        relations.get(concept_id, {}).get("broader", [])
                    ),
                    "narrower": "; ".join(
                        relations.get(concept_id, {}).get("narrower", [])
                    ),
                    "synonyms": "; ".join(
                        relations.get(concept_id, {}).get("synonyms", [])
                    ),
                    "ksh_link_url": f"https://lod.nl.go.kr/page/concept/{self._strip_namespace(concept_id)}",
                    "_sort_priority": priority,
                }
            )

        # DataFrame ìƒì„± ë° ì •ë ¬
        df = pd.DataFrame(rows)
        if not df.empty:
            df = df.sort_values("_sort_priority").drop(columns=["_sort_priority"])

        return df

    def get_ksh_entries(
        self, search_term=None, main_category=None, limit=None, exact_match=False
    ):
        """
        ğŸš€ [ë¦¬íŒ©í† ë§] KSH ê²€ìƒ‰ - ì‘ì€ ë©”ì„œë“œë“¤ë¡œ ë¶„í•´í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ

        Args:
            search_term: ê²€ìƒ‰ì–´
            main_category: ì£¼ì œ ì¹´í…Œê³ ë¦¬ í•„í„°
            limit: ê²°ê³¼ ê°œìˆ˜ ì œí•œ
            exact_match: ì™„ì „ ì¼ì¹˜ ê²€ìƒ‰ ì—¬ë¶€ (í˜„ì¬ ë¯¸ì‚¬ìš©)

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ DataFrame
        """
        conn = None
        try:
            conn = self.db_manager._get_concepts_connection()
            cursor = conn.cursor()

            logger.info(
                f"ğŸ” get_ksh_entries: search_term='{search_term}', main_category='{main_category}', limit={limit}"
            )

            # FTS5 í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='table' AND name='literal_props_fts'"
            )
            use_fts5 = cursor.fetchone() is not None

            if not use_fts5:
                logger.warning("âš ï¸ literal_props_fts í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()

            # ê²€ìƒ‰ì–´ ì „ì²˜ë¦¬
            # âœ… ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰: search_termì´ ì—†ì–´ë„ main_categoryê°€ ìˆìœ¼ë©´ ì§„í–‰
            if not search_term:
                if not main_category or main_category == "ì „ì²´":
                    return pd.DataFrame()
                # ì¹´í…Œê³ ë¦¬ ì „ìš© ê²€ìƒ‰ (ê²€ìƒ‰ì–´ ì—†ì´ ì¹´í…Œê³ ë¦¬ë§Œ)
                search_term = ""
                processed_term = ""
                fts_query = None
            else:
                processed_term = self.preprocess_search_term(search_term)
                # 1. FTS5 ì¿¼ë¦¬ ìƒì„±
                fts_query = self._build_fts5_query(processed_term)
                if not fts_query and not main_category:
                    return pd.DataFrame()

            # 2. FTS5 ê²€ìƒ‰ ì‹¤í–‰
            search_results = self._execute_fts5_search(
                cursor, fts_query, main_category, limit
            )
            logger.info(
                f"ğŸ“Š [FTS5 ìµœì í™”] ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ concept ë°œê²¬"
            )

            if not search_results:
                return pd.DataFrame()

            # 3. concept_id ëª©ë¡ ë° ë§¤ì¹­ ë§µ ìƒì„±
            concept_match_map = {
                row["concept_id"]: row["matched_value"] for row in search_results
            }
            concept_ids = list(concept_match_map.keys())

            # 4. ìƒì„¸ ì •ë³´ ì¡°íšŒ
            detail_results = self._fetch_concept_details(cursor, concept_ids)

            # 5. ê´€ê³„ì–´ ì¡°íšŒ
            relations = self._fetch_concept_relations(conn, concept_ids)

            # 6. DataFrame êµ¬ì„± ë° ì •ë ¬
            df = self._build_concepts_dataframe(
                detail_results, relations, concept_match_map, processed_term
            )

            return df.fillna("")

        except Exception as e:
            logger.error(f"âŒ KSH ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback

            traceback.print_exc()
            return pd.DataFrame()
        finally:
            if conn:
                conn.close()

    # ğŸ†• ê´€ê³„ì–´ ì¡°íšŒë¥¼ ìœ„í•œ í—¬í¼ ë©”ì„œë“œë“¤ ì¶”ê°€

    # ğŸ†• ê´€ê³„ì–´ ì¡°íšŒë¥¼ ìœ„í•œ í—¬í¼ ë©”ì„œë“œë“¤ ì¶”ê°€

    def get_ksh_entries_batch(self, search_terms: list):
        """
        ì£¼ì–´ì§„ ì—¬ëŸ¬ ì£¼ì œì–´ì— ëŒ€í•œ KSH ë°ì´í„°ë¥¼ í•œ ë²ˆì˜ ì¿¼ë¦¬ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.
        Args:
            search_terms (list): ì¡°íšŒí•  pure_subject_name ë¦¬ìŠ¤íŠ¸.
        Returns:
            pandas.DataFrame: ì¡°íšŒëœ ê²°ê³¼.
        """
        conn = None
        if not search_terms:
            return pd.DataFrame()
        try:
            conn = self.db_manager._get_ksh_connection()
            # SQL Injectionì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš©
            placeholders = ",".join("?" for _ in search_terms)
            query = (
                f"SELECT * FROM ksh_entries WHERE pure_subject_name IN ({placeholders})"
            )

            df = pd.read_sql_query(query, conn, params=search_terms)
            return df
        except Exception as e:
            print(f"ì˜¤ë¥˜: KSH ë°ì´í„° ì¼ê´„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return pd.DataFrame()
        finally:
            if conn:
                conn.close()

    def get_ksh_entries_batch_exact(self, terms_with_qualifiers):
        """
        [ìˆ˜ì •ë¨] ì—¬ëŸ¬ ìš©ì–´(ìˆ˜ì‹ì–´ í¬í•¨)ì— ëŒ€í•œ ì •í™•í•œ KSH í•­ëª©ì„ ì¼ê´„ ì¡°íšŒí•©ë‹ˆë‹¤.
        literal_props í…Œì´ë¸”ì—ì„œ valueë¥¼ ì§ì ‘ ë¹„êµí•˜ì—¬ ì •í™•ì„±ì„ ë†’ì…ë‹ˆë‹¤.

        Args:
            terms_with_qualifiers: [(pure_subject, parentheses, brackets), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸

        Returns:
            pandas.DataFrame: ì¡°íšŒëœ KSH í•­ëª©ë“¤ (ê¸°ì¡´ í˜•ì‹ í˜¸í™˜)
        """
        conn = None
        if not terms_with_qualifiers:
            return pd.DataFrame()

        try:
            conn = self.db_manager._get_concepts_connection()
            cursor = conn.cursor()

            # 1. ì…ë ¥ëœ ëª¨ë“  ì£¼ì œëª…(ìˆ˜ì‹ì–´ í¬í•¨) ë¬¸ìì—´ ìƒì„±
            full_subject_names = []
            input_map = {}  # (pure, paren, bracket) -> full_subject ë§¤í•‘
            for pure, paren, bracket in terms_with_qualifiers:
                name = pure
                if paren:
                    name += f"({paren})"
                if bracket:
                    name += f"[{bracket}]"
                full_subject_names.append(name)
                input_map[(pure, paren or "", bracket or "")] = name

            if not full_subject_names:
                return pd.DataFrame()

            # 2. literal_props í…Œì´ë¸”ì—ì„œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” value ê²€ìƒ‰ (IN ì ˆ ì‚¬ìš©)
            placeholders = ",".join(["?" for _ in full_subject_names])
            query = f"""
            SELECT
                lp.concept_id,
                lp.value AS matched_value,
                lp.prop
            FROM literal_props lp
            WHERE lp.value IN ({placeholders})
              AND lp.concept_id LIKE 'nlk:KSH%' -- nls: ì œì™¸
              AND lp.prop IN ('prefLabel', 'label', 'altLabel') -- ì£¼ìš” ë¼ë²¨ë§Œ ê³ ë ¤
            """
            cursor.execute(query, full_subject_names)
            prop_results = cursor.fetchall()

            # 3. concept_idë³„ë¡œ ê°€ì¥ ìš°ì„ ìˆœìœ„ ë†’ì€ í•­ëª© ì„ íƒ (prefLabel > label > altLabel)
            best_match_per_value = {}  # {full_subject: concept_id}
            temp_matches = {}  # {full_subject: (concept_id, priority)}
            prop_priority = {"prefLabel": 1, "label": 2, "altLabel": 3}

            for row in prop_results:
                concept_id = row["concept_id"]
                value = row["matched_value"]
                prop = row["prop"]
                priority = prop_priority.get(prop, 4)

                if value not in temp_matches or priority < temp_matches[value][1]:
                    temp_matches[value] = (concept_id, priority)

            best_match_per_value = {
                val: cid for val, (cid, pri) in temp_matches.items()
            }

            # 4. ì„ íƒëœ concept_idë“¤ì˜ ìƒì„¸ ì •ë³´ (ì¹´í…Œê³ ë¦¬, DDC, KDC) ì¡°íšŒ
            found_concept_ids = list(best_match_per_value.values())
            if not found_concept_ids:
                return pd.DataFrame()

            details_map = {}
            id_placeholders = ",".join(["?" for _ in found_concept_ids])
            detail_query = f"""
            SELECT
                c.concept_id,
                cm.main_category,
                dm.ddc_classification,
                km.kdc_like_classification,
                (
                    SELECT value FROM literal_props
                    WHERE concept_id = c.concept_id AND prop IN ('prefLabel', 'label')
                    ORDER BY CASE prop WHEN 'prefLabel' THEN 1 ELSE 2 END
                    LIMIT 1
                ) as pref_label -- ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] KSH ì½”ë“œì— ë§¤ì¹­ë˜ëŠ” ì‹¤ì œ prefLabelì„ ì¡°íšŒí•©ë‹ˆë‹¤.
            FROM concepts c
            LEFT JOIN category_mapping cm ON c.concept_id = cm.concept_id
            LEFT JOIN ddc_mapping dm ON c.concept_id = dm.concept_id
            LEFT JOIN kdc_mapping km ON c.concept_id = km.concept_id
            WHERE c.concept_id IN ({id_placeholders})
            """
            cursor.execute(detail_query, found_concept_ids)
            detail_results = cursor.fetchall()
            for row in detail_results:
                details_map[row["concept_id"]] = row

            # 5. ìµœì¢… DataFrame êµ¬ì„±
            data = []
            processed_inputs = set()  # ì…ë ¥ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€

            for pure, paren, bracket in terms_with_qualifiers:
                input_key = (pure, paren or "", bracket or "")
                if input_key in processed_inputs:
                    continue

                full_subject = input_map.get(input_key)
                if not full_subject:
                    continue

                concept_id = best_match_per_value.get(full_subject)
                if not concept_id:  # DBì—ì„œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í•­ëª© ëª» ì°¾ìŒ
                    continue

                details = details_map.get(concept_id)
                if not details:  # ìƒì„¸ ì •ë³´ ëª» ì°¾ìŒ (ì´ë¡ ìƒ ë°œìƒ ì•ˆ í•¨)
                    continue

                ksh_code = self._strip_namespace(concept_id)
                entry = {
                    # ì…ë ¥ê°’ ê¸°ì¤€ í•„ë“œ
                    "pure_subject_name": pure,
                    "qualifier_parentheses": paren or "",
                    "qualifier_square_brackets": bracket or "",
                    # DB ì¡°íšŒ ê²°ê³¼ í•„ë“œ
                    "ksh_code": ksh_code,
                    "pref_label": details["pref_label"]
                    or full_subject,  # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ì¡°íšŒëœ pref_labelì„ ë°˜í™˜ê°’ì— ì¶”ê°€í•©ë‹ˆë‹¤.
                    "main_category": details["main_category"] or "",
                    "classification_ddc": details["ddc_classification"] or "",
                    "classification_kdc_like": details["kdc_like_classification"] or "",
                    "ksh_link_url": f"https://lod.nl.go.kr/page/concept/{ksh_code}",  # LOD URLë¡œ ë³€ê²½
                }
                data.append(entry)
                processed_inputs.add(input_key)

            return pd.DataFrame(data)

        except Exception as e:
            print(f"ì˜¤ë¥˜: [ìˆ˜ì •ë¨] ì¼ê´„ KSH ì •í™• ë§¤ì¹­ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback

            traceback.print_exc()  # ìƒì„¸ ì—ëŸ¬ ì¶œë ¥
            return pd.DataFrame()
        finally:
            if conn:
                conn.close()

    # 7. ë‹¤êµ­ì–´ ê²€ìƒ‰ ë©”ì„œë“œ ì¶”ê°€ (ë³´ë„ˆìŠ¤)

    def get_ksh_entries_exact_match(
        self, pure_subject, parentheses=None, brackets=None, limit=1
    ):
        """
        ìˆ˜ì‹ì–´ê¹Œì§€ í¬í•¨í•œ ì •í™•í•œ KSH í•­ëª© ì¡°íšŒ
        ë™ìŒì´ì˜ì–´ êµ¬ë¶„ì„ ìœ„í•´ parenthesesì™€ bracketsê¹Œì§€ ë§¤ì¹­

        Args:
            pure_subject (str): ìˆœìˆ˜ ì£¼ì œëª… (ì˜ˆ: "ëˆˆ")
            parentheses (str, optional): ì›ê´„í˜¸ ìˆ˜ì‹ì–´ (ì˜ˆ: "eye", "snow")
            brackets (str, optional): ê°ê´„í˜¸ ìˆ˜ì‹ì–´ (ì˜ˆ: "è‹±èª", "è‡ºæœ¬")
            limit (int): ìµœëŒ€ ë°˜í™˜ ê°œìˆ˜

        Returns:
            pandas.DataFrame: ë§¤ì¹­ëœ KSH í•­ëª©ë“¤
        """
        conn = None
        try:
            conn = self.db_manager._get_ksh_connection()

            # ê¸°ë³¸ ì¡°ê±´: pure_subject_name ë§¤ì¹­
            conditions = ["pure_subject_name = ?"]
            params = [pure_subject]

            # ê´„í˜¸ ì¡°ê±´ ì¶”ê°€
            if parentheses and parentheses.strip():
                conditions.append("qualifier_parentheses = ?")
                params.append(parentheses.strip())
            else:
                conditions.append(
                    "(qualifier_parentheses IS NULL OR qualifier_parentheses = '')"
                )

            # ê°ê´„í˜¸ ì¡°ê±´ ì¶”ê°€
            if brackets and brackets.strip():
                conditions.append("qualifier_square_brackets = ?")
                params.append(brackets.strip())
            else:
                conditions.append(
                    "(qualifier_square_brackets IS NULL OR qualifier_square_brackets = '')"
                )

            query = f"""
            SELECT * FROM ksh_entries
            WHERE {' AND '.join(conditions)}
            ORDER BY id ASC
            LIMIT ?
            """
            params.append(limit)

            df_result = pd.read_sql_query(query, conn, params=params)
            return df_result

        except Exception as e:
            print(f"ì˜¤ë¥˜: ì •í™•í•œ ë§¤ì¹­ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return pd.DataFrame()
        finally:
            if conn:
                conn.close()

    # 5. get_ksh_entries_batch_exact ë©”ì„œë“œ êµì²´

    def search_integrated_ksh(self, search_term):
        """
        ğŸ”§ ìˆ˜ì •ëœ í†µí•© KSH ê²€ìƒ‰ ë¡œì§ - DDC ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°ë„ ì •í™• ì¸ì‹
        """
        start_time = time.time()
        logger.info(f"ğŸŸ¢ [TIMING] search_integrated_ksh ì‹œì‘: '{search_term}'")

        term = search_term.strip()

        # 1. ê²€ìƒ‰ì–´ ìœ í˜• ë¶„ì„ - DDC ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°ë„ ì¸ì‹
        # ê¸°ì¡´: r"\b\d{1,3}(?:\.\d+)?\b"
        # ìˆ˜ì •: ìˆœìˆ˜ ìˆ«ì 3ìë¦¬ë„ DDCë¡œ ì¸ì‹í•˜ë„ë¡ ê°œì„ 
        ddc_codes = []

        # DDC íŒ¨í„´: 3ìë¦¬ ìˆ«ì, ì†Œìˆ˜ì  í¬í•¨ ìˆ«ì (001, 004, 650, 650.1 ë“±)
        ddc_pattern_matches = re.findall(r"\b\d{1,3}(?:\.\d+)?\b", term)

        # ê²€ìƒ‰ì–´ê°€ ìˆœìˆ˜ ìˆ«ìë¡œë§Œ êµ¬ì„±ë˜ì–´ ìˆê³  1~4ìë¦¬ì¸ ê²½ìš° DDCë¡œ ê°„ì£¼
        if term.isdigit() and 1 <= len(term) <= 4:
            ddc_codes = [term]
            logger.info(f"ğŸ”µ [DDC_DETECT] ìˆœìˆ˜ ìˆ«ì '{term}' â†’ DDC ì½”ë“œë¡œ ì¸ì‹")
        elif ddc_pattern_matches:
            # ê¸°ì¡´ íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ ì‚¬ìš©
            for match in ddc_pattern_matches:
                # 3ìë¦¬ ì´í•˜ ì •ìˆ˜ì´ê±°ë‚˜ ì†Œìˆ˜ì ì´ ìˆëŠ” ê²½ìš°ë§Œ DDCë¡œ ì¸ì‹
                if "." in match or (match.isdigit() and len(match) <= 3):
                    ddc_codes.append(match)

        ksh_codes = [t.strip() for t in re.findall(r"\bKSH\d+\b", term, re.IGNORECASE)]

        # DDC, KSH ì½”ë“œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¥¼ ì£¼ì œëª…/í‚¤ì›Œë“œë¡œ ê°„ì£¼
        keywords_str = term
        for code in ddc_codes + ksh_codes:
            keywords_str = keywords_str.replace(code, "")
        keywords = [kw.strip() for kw in keywords_str.split(",") if kw.strip()]

        logger.info(f"ğŸ” [TIMING] ê²€ìƒ‰ì–´ ë¶„ì„ ì™„ë£Œ ({time.time() - start_time:.3f}ì´ˆ)")
        logger.info(f"   - DDC ì½”ë“œ: {ddc_codes}")
        logger.info(f"   - KSH ì½”ë“œ: {ksh_codes}")
        logger.info(f"   - í‚¤ì›Œë“œ: {keywords}")

        # ê²°ê³¼ DataFrameë“¤
        df_concept_search = pd.DataFrame()  # ìƒë‹¨ íŠ¸ë¦¬ë·°ìš©
        df_bibliographic = pd.DataFrame()  # í•˜ë‹¨ íŠ¸ë¦¬ë·°ìš©

        # ê²€ìƒ‰ íƒ€ì…ì„ ë°˜í™˜ê°’ì— í¬í•¨í•˜ê¸° ìœ„í•´ ì €ì¥
        search_type = None

        # 2. ê²€ìƒ‰ì–´ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ê²€ìƒ‰ ì‹¤í–‰
        # DDC ì½”ë“œê°€ ìˆì„ ê²½ìš° ì„œì§€ DBë§Œ ê²€ìƒ‰ (ì»¨ì…‰ DB ë¹„í™œì„±í™”)
        if ddc_codes:
            search_type = "ddc"
            logger.info(f"ğŸ”µ [TIMING] DDC ê²€ìƒ‰ ì‹œì‘ (ì„œì§€ DBë§Œ)...")
            df_bibliographic = self._search_by_ddc_with_fallback(ddc_codes)
            logger.info(
                f"ğŸ”µ [TIMING] DDC ê²€ìƒ‰ ì™„ë£Œ ({time.time() - start_time:.3f}ì´ˆ, {len(df_bibliographic)}ê°œ ê²°ê³¼)"
            )

        # KSH ì½”ë“œê°€ ìˆì„ ê²½ìš° ì„œì§€ DBë§Œ ê²€ìƒ‰ (ì»¨ì…‰ DB ë¹„í™œì„±í™”)
        elif ksh_codes:
            search_type = "ksh"
            logger.info(f"ğŸŸ¡ [TIMING] KSH ì½”ë“œ ê²€ìƒ‰ ì‹œì‘ (ì„œì§€ DBë§Œ)...")
            df_bibliographic = self._search_by_ksh_code(ksh_codes)
            logger.info(
                f"ğŸŸ¡ [TIMING] KSH ì½”ë“œ ê²€ìƒ‰ ì™„ë£Œ ({time.time() - start_time:.3f}ì´ˆ, {len(df_bibliographic)}ê°œ ê²°ê³¼)"
            )

        # DDC/KSH ì½”ë“œê°€ ì—†ê³  í‚¤ì›Œë“œë§Œ ìˆëŠ” ê²½ìš° (ìˆ˜ì •ëœ ë¡œì§)
        elif keywords:
            search_type = "keyword"
            # -------------------
            # âœ… [í•µì‹¬ ìµœì í™”] ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ë£¨í”„ë¡œ ê°œë³„ ê²€ìƒ‰í•˜ëŠ” ëŒ€ì‹ ,
            # ì½¤ë§ˆë¡œ ì—°ê²°ëœ ì „ì²´ ê²€ìƒ‰ì–´ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ DB ì¡°íšŒë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.
            concept_start = time.time()
            logger.info(
                f"ğŸŸ  [TIMING] NLK Concept DB ë° ì„œì§€ DB ë™ì‹œ ê²€ìƒ‰ ì‹œì‘ (í†µí•© í‚¤ì›Œë“œ)..."
            )

            # 1. ì»¨ì…‰ DB ê²€ìƒ‰ (ì „ì²´ ê²€ìƒ‰ì–´ í•œ ë²ˆì— ì „ë‹¬)
            try:
                from Search_KSH_Local import KshLocalSearcher

                searcher = KshLocalSearcher(self.db_manager)
                # search_concepts -> get_ksh_entriesëŠ” ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ OR ì¡°ê±´ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì´ ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
                df_concept_search = searcher.search_concepts(keyword=search_term)
            except Exception as e:
                logger.error(f"ì˜¤ë¥˜: '{search_term}' ì»¨ì…‰ DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                df_concept_search = (
                    pd.DataFrame()
                )  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ DataFrameìœ¼ë¡œ ì´ˆê¸°í™”

            # 2. ì„œì§€ DB ê²€ìƒ‰ (ìˆœì°¨ ì²˜ë¦¬ - SQLite Write Lockìœ¼ë¡œ ì¸í•´ ë³‘ë ¬ ì²˜ë¦¬ ë¬´ì˜ë¯¸)
            # âš¡ [ì„±ëŠ¥ ê°œì„ ] ë¶ˆí•„ìš”í•œ ThreadPoolExecutor ì œê±°
            bibliographic_dfs = []
            try:
                for kw in keywords:
                    try:
                        df_b = self.get_bibliographic_by_subject_name(kw)
                        if not df_b.empty:
                            bibliographic_dfs.append(df_b)
                    except Exception as e:
                        logger.error(f"ì˜¤ë¥˜: '{kw}' ì„œì§€ DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            except Exception as e:
                logger.error(f"ì˜¤ë¥˜: ì„œì§€ DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

            # 3. ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
            # df_concept_searchëŠ” ì´ë¯¸ ë‹¨ì¼ DataFrameì´ë¯€ë¡œ ë³„ë„ í†µí•©ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
            if not df_concept_search.empty:
                logger.info(
                    f"ğŸŸ  [TIMING] NLK Concept DB ê²€ìƒ‰ ì™„ë£Œ ({time.time() - concept_start:.3f}ì´ˆ, {len(df_concept_search)}ê°œ ê²°ê³¼)"
                )

            if bibliographic_dfs:
                df_bibliographic = pd.concat(
                    bibliographic_dfs, ignore_index=True
                ).drop_duplicates(subset=["identifier"])
                logger.info(
                    f"ğŸŸ£ [TIMING] ì„œì§€ DB ê²€ìƒ‰ ì™„ë£Œ ({time.time() - concept_start:.3f}ì´ˆ, {len(df_bibliographic)}ê°œ ê²°ê³¼)"
                )
            else:
                # bibliographic_dfsê°€ ë¹„ì–´ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ df_bibliographicì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
                df_bibliographic = pd.DataFrame()
            # -------------------

        total_time = time.time() - start_time
        logger.info(
            f"ğŸ [TIMING] search_integrated_ksh ì™„ë£Œ: {total_time:.3f}ì´ˆ, Concept DB: {len(df_concept_search)}ê°œ, Biblio DB: {len(df_bibliographic)}ê°œ ê²°ê³¼"
        )

        # ğŸ¯ ê²€ìƒ‰ íƒ€ì…ë„ í•¨ê»˜ ë°˜í™˜
        return df_concept_search.fillna(""), df_bibliographic.fillna(""), search_type

    def search_integrated_ksh_with_relations(self, hierarchy_keywords):
        """
        ê³„ì¸µì  í‚¤ì›Œë“œ + ê´€ê³„ ì •ë³´ í™•ì¥ ê²€ìƒ‰
        ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ì¶° êµ¬í˜„
        """
        all_keywords = set()

        # ê³„ì¸µë³„ í‚¤ì›Œë“œ ìˆ˜ì§‘
        if isinstance(hierarchy_keywords, dict):
            for level, keywords in hierarchy_keywords.items():
                if isinstance(keywords, list):
                    all_keywords.update([k.strip() for k in keywords if k.strip()])
        elif isinstance(hierarchy_keywords, list):
            all_keywords.update([k.strip() for k in hierarchy_keywords if k.strip()])
        elif isinstance(hierarchy_keywords, str):
            all_keywords.add(hierarchy_keywords.strip())

        # Concept DB ê´€ê³„ ì •ë³´ë¡œ í‚¤ì›Œë“œ í™•ì¥
        expanded_keywords = set(all_keywords)

        for keyword in list(all_keywords)[:5]:  # ì„±ëŠ¥ì„ ìœ„í•´ ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œë§Œ í™•ì¥
            try:
                relations = self.get_concept_relations(keyword)

                # ìƒìœ„ì–´, í•˜ìœ„ì–´, ê´€ë ¨ì–´ë¥¼ í™•ì¥ í‚¤ì›Œë“œì— ì¶”ê°€ (ê° íƒ€ì…ë‹¹ ìµœëŒ€ 2ê°œ)
                for relation_type, terms in relations.items():
                    if relation_type in ["broader", "narrower", "related"] and terms:
                        expanded_keywords.update(terms[:2])

            except Exception as e:
                print(f"ê²½ê³ : '{keyword}' ê´€ê³„ í™•ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        # ë„ˆë¬´ ë§ìœ¼ë©´ ì œí•œ (ì„±ëŠ¥ ê³ ë ¤)
        final_keywords = list(expanded_keywords)[:12]
        expanded_keyword_string = ", ".join(final_keywords)

        print(
            f"ğŸ”— í‚¤ì›Œë“œ í™•ì¥ ì™„ë£Œ: ì›ë³¸ {len(all_keywords)}ê°œ â†’ í™•ì¥ {len(final_keywords)}ê°œ"
        )
        print(f"   í™•ì¥ëœ í‚¤ì›Œë“œ: {expanded_keyword_string}")

        # í™•ì¥ëœ í‚¤ì›Œë“œë“¤ë¡œ í†µí•© ê²€ìƒ‰
        return self.search_integrated_ksh(expanded_keyword_string)

    def search_ksh_by_language(self, keyword, language="ko", limit=1000):
        """
        ğŸš€ ìµœì í™”ëœ ë‹¤êµ­ì–´ ê²€ìƒ‰: value_normalized ì»¬ëŸ¼ í™œìš©
        """
        conn = None
        try:
            conn = self.db_manager._get_concepts_connection()
            cursor = conn.cursor()

            # ê²€ìƒ‰ì–´ ì •ê·œí™”
            normalized_keyword = keyword.replace(" ", "")

            if language == "en":
                # ì˜ì–´: ASCII ë¬¸ìë§Œ í¬í•¨ëœ altLabel, value_normalized ì‚¬ìš©
                search_query = """
                SELECT DISTINCT c.concept_id, lp_match.value as matched_term, lp_pref.value as pref_label
                FROM concepts c
                LEFT JOIN literal_props lp_pref ON c.concept_id = lp_pref.concept_id AND lp_pref.prop = 'prefLabel'
                LEFT JOIN literal_props lp_match ON c.concept_id = lp_match.concept_id AND lp_match.prop = 'altLabel'
                WHERE lp_match.value_normalized LIKE ?
                AND lp_match.value NOT GLOB '*[ã„±-ã…£ê°€-í£]*'
                LIMIT ?
                """
            else:
                # í•œêµ­ì–´: ëª¨ë“  ë¼ë²¨ì—ì„œ ê²€ìƒ‰, value_normalized ì‚¬ìš©
                search_query = """
                SELECT DISTINCT c.concept_id, lp_match.value as matched_term, lp_pref.value as pref_label
                FROM concepts c
                LEFT JOIN literal_props lp_pref ON c.concept_id = lp_pref.concept_id AND lp_pref.prop = 'prefLabel'
                LEFT JOIN literal_props lp_match ON c.concept_id = lp_match.concept_id
                    AND lp_match.prop IN ('prefLabel', 'label', 'altLabel')
                WHERE lp_match.value_normalized LIKE ?
                LIMIT ?
                """

            cursor.execute(search_query, (f"%{normalized_keyword}%", limit))
            results = cursor.fetchall()

            # DataFrame êµ¬ì„±
            data = []
            for row in results:
                concept_id = row["concept_id"]
                ksh_code = self._strip_namespace(concept_id)
                pref_label = row["pref_label"] or ""

                entry = {
                    "id": len(data) + 1,
                    "original_subject": self._format_ksh_display(
                        concept_id, pref_label
                    ),
                    "pure_subject_name": pref_label,
                    "matched_term": row["matched_term"],
                    "ksh_code": ksh_code,
                    "language": language,
                    "ksh_link_url": f"https://librarian.nl.go.kr/LI/contents/L20201000000.do?controlNo={ksh_code}",
                }
                data.append(entry)

            return pd.DataFrame(data)

        except Exception as e:
            print(f"ì˜¤ë¥˜: ë‹¤êµ­ì–´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return pd.DataFrame()
        finally:
            if conn:
                conn.close()

    # 3. ìƒˆ DB ì²˜ë¦¬ìš© í—¬í¼ ë©”ì„œë“œë“¤ ì¶”ê°€
