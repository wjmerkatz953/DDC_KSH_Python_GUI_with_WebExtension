"""
get_ksh_entries ë©”ì„œë“œë¥¼ ì‘ì€ ë©”ì„œë“œë“¤ë¡œ ë¶„í•´í•˜ëŠ” ë¦¬íŒ©í† ë§ ìŠ¤í¬ë¦½íŠ¸
472ì¤„ â†’ 6ê°œì˜ ì‘ì€ ë©”ì„œë“œë¡œ ë¶„ë¦¬
"""

# ë¶„í•´í•  ë©”ì„œë“œë“¤:
# 1. _build_fts5_query(processed_term) -> str
# 2. _execute_fts5_search(cursor, fts_query, main_category, limit) -> list
# 3. _fetch_concept_details(cursor, concept_ids) -> list
# 4. _fetch_concept_relations(conn, concept_ids) -> dict
# 5. _build_concepts_dataframe(detail_results, relations, concept_match_map, processed_term) -> DataFrame
# 6. get_ksh_entries (ë©”ì¸ ì¡°ì •ì ë©”ì„œë“œ) -> DataFrame

refactored_methods = '''
    def _build_fts5_query(self, processed_term: str) -> str:
        """
        FTS5 ê²€ìƒ‰ ì¿¼ë¦¬ ë¬¸ìì—´ ìƒì„±

        Args:
            processed_term: ì „ì²˜ë¦¬ëœ ê²€ìƒ‰ì–´

        Returns:
            FTS5 MATCH ì¿¼ë¦¬ ë¬¸ìì—´
        """
        normalized_term = processed_term.replace(" ", "")

        if "," in processed_term:
            # ë‹¤ì¤‘ ê²€ìƒ‰ì–´: "í•œêµ­" OR "ê²½ì œ" OR ...
            terms = [term.strip().replace(" ", "") for term in processed_term.split(",") if term.strip()]

            fts_terms = []
            for t in terms:
                sanitized_t = re.sub(r'[^\\w]', '', t)
                if sanitized_t:
                    fts_terms.append(f'"{sanitized_t}" OR {sanitized_t}*')

            return " OR ".join(fts_terms)
        else:
            # ë‹¨ì¼ ê²€ìƒ‰ì–´: "í•œêµ­" OR í•œêµ­*
            sanitized_term = re.sub(r'[^\\w]', '', normalized_term)
            if sanitized_term:
                return f'"{sanitized_term}" OR {sanitized_term}*'
            else:
                return ""


    def _execute_fts5_search(self, cursor, fts_query: str, main_category: str = None, limit: int = None) -> list:
        """
        FTS5 ì „ë¬¸ ê²€ìƒ‰ ì‹¤í–‰

        Args:
            cursor: ë°ì´í„°ë² ì´ìŠ¤ ì»¤ì„œ
            fts_query: FTS5 MATCH ì¿¼ë¦¬ ë¬¸ìì—´
            main_category: ì£¼ì œ ì¹´í…Œê³ ë¦¬ í•„í„°
            limit: ê²°ê³¼ ê°œìˆ˜ ì œí•œ

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [(concept_id, matched_value), ...]
        """
        base_query = """
        SELECT DISTINCT
            lp.concept_id,
            lp.value as matched_value,
            lp.prop,
            CASE lp.prop WHEN 'prefLabel' THEN 1 WHEN 'label' THEN 2 WHEN 'altLabel' THEN 3 ELSE 4 END as prop_priority
        FROM literal_props_fts fts
        JOIN literal_props lp ON fts.rowid = lp.rowid
        LEFT JOIN category_mapping cm ON lp.concept_id = cm.concept_id
        WHERE lp.concept_id LIKE 'nlk:KSH%'
        AND lp.concept_id NOT LIKE 'nls:%'
        AND lp.prop IN ('prefLabel', 'label', 'altLabel')
        AND fts.value_normalized MATCH ?
        """

        params = [fts_query]

        # ì£¼ì œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        if main_category and main_category != "ì „ì²´":
            base_query += " AND cm.main_category = ?"
            params.append(main_category)

        base_query += """
        ORDER BY
            fts.rank ASC,
            prop_priority ASC,
            LENGTH(lp.value) ASC,
            lp.value ASC
        """

        # WITH + WINDOW FUNCTIONìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        optimized_query = f"""
        WITH RankedResults AS (
            {base_query}
        )
        SELECT DISTINCT
            concept_id,
            FIRST_VALUE(matched_value) OVER (
                PARTITION BY concept_id
                ORDER BY prop_priority ASC, LENGTH(matched_value) ASC
            ) as matched_value
        FROM RankedResults
        """

        cursor.execute(optimized_query, params)
        all_results = cursor.fetchall()

        # Pythonì—ì„œ LIMIT ì ìš©
        return all_results[:limit] if limit else all_results


    def _fetch_concept_details(self, cursor, concept_ids: list) -> list:
        """
        ê°œë…ë“¤ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ë°°ì¹˜)

        Args:
            cursor: ë°ì´í„°ë² ì´ìŠ¤ ì»¤ì„œ
            concept_ids: ì¡°íšŒí•  concept_id ë¦¬ìŠ¤íŠ¸

        Returns:
            ìƒì„¸ ì •ë³´ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        placeholders = ",".join("?" for _ in concept_ids)
        detail_query = f"""
        SELECT
            c.concept_id,
            (
                SELECT value FROM literal_props
                WHERE concept_id = c.concept_id AND prop IN ('prefLabel', 'label')
                ORDER BY CASE prop WHEN 'prefLabel' THEN 1 ELSE 2 END
                LIMIT 1
            ) as pref_label,
            cm.main_category,
            dm.ddc_classification,
            km.kdc_like_classification
        FROM concepts c
        LEFT JOIN category_mapping cm ON c.concept_id = cm.concept_id
        LEFT JOIN ddc_mapping dm ON c.concept_id = dm.concept_id
        LEFT JOIN kdc_mapping km ON c.concept_id = km.concept_id
        WHERE c.concept_id IN ({placeholders})
        """
        cursor.execute(detail_query, concept_ids)
        return cursor.fetchall()


    def _fetch_concept_relations(self, conn, concept_ids: list) -> dict:
        """
        ê°œë…ë“¤ì˜ ê´€ê³„ì–´ ì¡°íšŒ (broader, narrower, related, synonyms)

        Args:
            conn: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            concept_ids: ì¡°íšŒí•  concept_id ë¦¬ìŠ¤íŠ¸

        Returns:
            {concept_id: {'broader': [...], 'narrower': [...], 'related': [...], 'synonyms': [...]}}
        """
        relations = {}

        for cid in concept_ids:
            relations[cid] = {
                'broader': self._get_broader_for_concept(conn, cid),
                'narrower': self._get_narrower_for_concept(conn, cid),
                'related': self._get_related_for_concept(conn, cid),
                'synonyms': self._get_synonyms_for_concept(conn, cid)
            }

        return relations


    def _calculate_match_priority(self, matched_value: str, search_term: str) -> tuple:
        """
        ë§¤ì¹­ ìš°ì„ ìˆœìœ„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        ë©”ë¥´ì¹´ì¸ ë‹˜ ìš”êµ¬ì‚¬í•­:
        1ìˆœìœ„: ì™„ë²½ ë§¤ì¹­(ì „ë°©ë§¤ì¹­ + ê¸€ì ìˆ˜ê¹Œì§€ ì™„ë²½ ë§¤ì¹­)
        2ìˆœìœ„: ì „ë°© ë§¤ì¹­ì¸ë° ê¸€ììˆ˜ê°€ ì§§ì€ ê²ƒ
        3ìˆœìœ„: ì „ë°© ë§¤ì¹­ì´ ì•„ë‹ˆë©´ì„œ ê¸€ììˆ˜ê°€ ì§§ì€ ê²ƒ
        4ìˆœìœ„: ì›ê´„í˜¸ ì•ˆ ë§¤ì¹­

        Returns:
            tuple: (priority, length, alphabetical_sort_key)
        """
        if not matched_value or not search_term:
            return (5, 9999, matched_value or "")

        # í•œê¸€ ì—¬ë¶€ ê²€ì‚¬
        has_korean = bool(re.search(r"[\\uac00-\\ud7a3]", search_term))

        # ìˆœìˆ˜ ì£¼ì œëª… ì¶”ì¶œ (ê´„í˜¸/ê°ê´„í˜¸ ì œê±°)
        pure_subject = self._get_clean_subject_for_sorting(matched_value)

        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì¶”ì¶œ
        parentheses_content = ""
        brackets_content = ""

        paren_match = re.search(r"\\(([^)]*)\\)", matched_value)
        if paren_match:
            parentheses_content = paren_match.group(1)

        bracket_match = re.search(r"\\[([^\\]]*)\\]", matched_value)
        if bracket_match:
            brackets_content = bracket_match.group(1)

        # í•œê¸€ê³¼ ì˜ì–´ì— ë”°ë¥¸ ë‹¤ë¥¸ ì •ê·œí™” ë°©ì‹ ì ìš©
        if has_korean:
            # í•œê¸€ ê²€ìƒ‰: ë‹¨ìˆ˜í™” ì—†ì´ ê³µë°± ì œê±° + ì†Œë¬¸ìë§Œ
            norm_search = re.sub(r"\\s+", "", search_term.lower())
            norm_pure = re.sub(r"\\s+", "", pure_subject.lower())
            norm_paren = re.sub(r"\\s+", "", parentheses_content.lower())
            norm_bracket = re.sub(r"\\s+", "", brackets_content.lower())
        else:
            # ì˜ì–´ ê²€ìƒ‰: ê¸°ì¡´ _norm_for_compare ë¡œì§ ì‚¬ìš© (ë‹¨ìˆ˜í™” í¬í•¨)
            def _norm_for_compare_en(s: str) -> str:
                if not s:
                    return ""
                base = self._get_clean_subject_for_sorting(str(s))
                base = re.sub(r"\\s+", "", base).lower()
                try:
                    base = inflection.singularize(base)
                except Exception:
                    pass
                return base

            norm_search = _norm_for_compare_en(search_term)
            norm_pure = _norm_for_compare_en(pure_subject)
            norm_paren = _norm_for_compare_en(parentheses_content)
            norm_bracket = _norm_for_compare_en(brackets_content)

        # 1ìˆœìœ„: ì™„ë²½ ë§¤ì¹­ (ìˆœìˆ˜ ì£¼ì œëª…ì—ì„œ ì „ë°©ë§¤ì¹­ + ê¸¸ì´ ì¼ì¹˜)
        if norm_pure.startswith(norm_search) and len(norm_pure) == len(norm_search):
            return (1, len(pure_subject), pure_subject.lower())

        # 2ìˆœìœ„: ì „ë°© ë§¤ì¹­ì´ë©´ì„œ ìˆœìˆ˜ ì£¼ì œëª…ì´ ì§§ì€ ê²ƒ
        if norm_pure.startswith(norm_search):
            return (2, len(pure_subject), pure_subject.lower())

        # 3ìˆœìœ„: ìˆœìˆ˜ ì£¼ì œëª…ì— í¬í•¨ë˜ì§€ë§Œ ì „ë°©ë§¤ì¹­ì´ ì•„ë‹Œ ê²ƒ (ì§§ì€ ìˆœ)
        if norm_search in norm_pure:
            return (3, len(pure_subject), pure_subject.lower())

        # 4ìˆœìœ„: ì›ê´„í˜¸ ì•ˆì—ì„œ ë§¤ì¹­
        if norm_search in norm_paren or norm_paren.startswith(norm_search):
            return (4, len(matched_value), matched_value.lower())

        # 5ìˆœìœ„: ê°ê´„í˜¸ ì•ˆì—ì„œ ë§¤ì¹­
        if norm_search in norm_bracket or norm_bracket.startswith(norm_search):
            return (4, len(matched_value), matched_value.lower())

        # 6ìˆœìœ„: ê¸°íƒ€ (ë§¤ì¹­ë˜ì§€ ì•ŠìŒ)
        return (5, len(matched_value), matched_value.lower())


    def _build_concepts_dataframe(self, detail_results: list, relations: dict,
                                   concept_match_map: dict, processed_term: str) -> pd.DataFrame:
        """
        ê°œë… ê²€ìƒ‰ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ êµ¬ì„±

        Args:
            detail_results: ìƒì„¸ ì •ë³´ ê²°ê³¼
            relations: ê´€ê³„ì–´ ë”•ì…”ë„ˆë¦¬
            concept_match_map: {concept_id: matched_value}
            processed_term: ì „ì²˜ë¦¬ëœ ê²€ìƒ‰ì–´

        Returns:
            ì •ë ¬ ë° í¬ë§·íŒ…ëœ DataFrame
        """
        # ë‹¤ì¤‘ ê²€ìƒ‰ì–´ ì²˜ë¦¬
        first_search_term = processed_term.split(",")[0].strip() if "," in processed_term else processed_term

        # ê²°ê³¼ êµ¬ì„±
        rows = []
        for row in detail_results:
            concept_id = row["concept_id"]
            matched_value = concept_match_map.get(concept_id, "")

            # ìš°ì„ ìˆœìœ„ ê³„ì‚°
            priority = self._calculate_match_priority(matched_value, first_search_term)

            rows.append({
                "concept_id": concept_id,
                "subject": row["pref_label"] or matched_value,
                "main_category": row["main_category"] or "",
                "classification_ddc": row["ddc_classification"] or "",
                "classification_kdc_like": row["kdc_like_classification"] or "",
                "matched": matched_value,
                "related": "; ".join(relations.get(concept_id, {}).get('related', [])),
                "broader": "; ".join(relations.get(concept_id, {}).get('broader', [])),
                "narrower": "; ".join(relations.get(concept_id, {}).get('narrower', [])),
                "synonyms": "; ".join(relations.get(concept_id, {}).get('synonyms', [])),
                "ksh_link_url": f"https://lod.nl.go.kr/page/concept/{self._strip_namespace(concept_id)}",
                "_sort_priority": priority
            })

        # DataFrame ìƒì„± ë° ì •ë ¬
        df = pd.DataFrame(rows)
        if not df.empty:
            df = df.sort_values("_sort_priority").drop(columns=["_sort_priority"])

        return df


    def get_ksh_entries(
        self, search_term=None, main_category=None, limit=None, exact_match=False
    ):
        """
        ğŸš€ [ë¦¬íŒ©í† ë§] KSH ê²€ìƒ‰ - ì‘ì€ ë©”ì„œë“œë“¤ë¡œ ë¶„í•´í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ

        Args:
            search_term: ê²€ìƒ‰ì–´
            main_category: ì£¼ì œ ì¹´í…Œê³ ë¦¬ í•„í„°
            limit: ê²°ê³¼ ê°œìˆ˜ ì œí•œ
            exact_match: ì™„ì „ ì¼ì¹˜ ê²€ìƒ‰ ì—¬ë¶€ (í˜„ì¬ ë¯¸ì‚¬ìš©)

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ DataFrame
        """
        conn = None
        try:
            conn = self.db_manager._get_concepts_connection()
            cursor = conn.cursor()

            logger.info(
                f"ğŸ” get_ksh_entries: search_term='{search_term}', main_category='{main_category}', limit={limit}"
            )

            # FTS5 í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='literal_props_fts'")
            use_fts5 = cursor.fetchone() is not None

            if not use_fts5:
                logger.warning("âš ï¸ literal_props_fts í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()

            # ê²€ìƒ‰ì–´ ì „ì²˜ë¦¬
            if not search_term:
                return pd.DataFrame()

            processed_term = self.preprocess_search_term(search_term)

            # 1. FTS5 ì¿¼ë¦¬ ìƒì„±
            fts_query = self._build_fts5_query(processed_term)
            if not fts_query:
                return pd.DataFrame()

            # 2. FTS5 ê²€ìƒ‰ ì‹¤í–‰
            search_results = self._execute_fts5_search(cursor, fts_query, main_category, limit)
            logger.info(f"ğŸ“Š [FTS5 ìµœì í™”] ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ concept ë°œê²¬")

            if not search_results:
                return pd.DataFrame()

            # 3. concept_id ëª©ë¡ ë° ë§¤ì¹­ ë§µ ìƒì„±
            concept_match_map = {row["concept_id"]: row["matched_value"] for row in search_results}
            concept_ids = list(concept_match_map.keys())

            # 4. ìƒì„¸ ì •ë³´ ì¡°íšŒ
            detail_results = self._fetch_concept_details(cursor, concept_ids)

            # 5. ê´€ê³„ì–´ ì¡°íšŒ
            relations = self._fetch_concept_relations(conn, concept_ids)

            # 6. DataFrame êµ¬ì„± ë° ì •ë ¬
            df = self._build_concepts_dataframe(detail_results, relations, concept_match_map, processed_term)

            return df.fillna("")

        except Exception as e:
            logger.error(f"âŒ KSH ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
        finally:
            if conn:
                conn.close()
'''

print("=" * 60)
print("get_ksh_entries ë¦¬íŒ©í† ë§ ê³„íš")
print("=" * 60)
print("\nê¸°ì¡´: get_ksh_entries 1ê°œ ë©”ì„œë“œ (472ì¤„)")
print("\në¶„í•´ í›„: 7ê°œ ë©”ì„œë“œ")
print("  1. _build_fts5_query (~30ì¤„) - FTS5 ì¿¼ë¦¬ ë¬¸ìì—´ ìƒì„±")
print("  2. _execute_fts5_search (~60ì¤„) - FTS5 ê²€ìƒ‰ ì‹¤í–‰")
print("  3. _fetch_concept_details (~25ì¤„) - ìƒì„¸ ì •ë³´ ì¡°íšŒ")
print("  4. _fetch_concept_relations (~15ì¤„) - ê´€ê³„ì–´ ì¡°íšŒ")
print("  5. _calculate_match_priority (~90ì¤„) - ë§¤ì¹­ ìš°ì„ ìˆœìœ„ ê³„ì‚°")
print("  6. _build_concepts_dataframe (~50ì¤„) - DataFrame êµ¬ì„±")
print("  7. get_ksh_entries (~60ì¤„) - ë©”ì¸ ì¡°ì •ì")
print("\nì´í•©: ~330ì¤„ (140ì¤„ ì ˆê°, ì¤‘ë³µ ì œê±°)")
print("\në¦¬íŒ©í† ë§ ë©”ì„œë“œë¥¼ refactored_get_ksh_entries.txtì— ì €ì¥...")

with open(r'c:\Python\refactored_get_ksh_entries.txt', 'w', encoding='utf-8') as f:
    f.write(refactored_methods)

print("âœ… ì™„ë£Œ! refactored_get_ksh_entries.txt íŒŒì¼ í™•ì¸ í›„ ìˆ˜ë™ìœ¼ë¡œ ì ìš©í•˜ì„¸ìš”.")
