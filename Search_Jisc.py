import requests
import json
import time
from urllib.parse import urlencode


def search_jisc_like_browser(
    author=None,
    title=None,
    subject=None,
    keyword=None,
    publisher=None,
    isbn=None,
    publisher_place=None,
    date=None,
):
    """
    ì‹¤ì œ ì›¹ë¸Œë¼ìš°ì €ì²˜ëŸ¼ JISC Library Hub Discoverì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ì›¹ì‚¬ì´íŠ¸ì˜ ì‹¤ì œ ê²€ìƒ‰ ë°©ì‹ì„ ëª¨ë°©í•©ë‹ˆë‹¤.

    Args:
        author (str): ì €ìëª…
        title (str): ì œëª©
        subject (str): ì£¼ì œ
        keyword (str): í‚¤ì›Œë“œ
        publisher (str): ì¶œíŒì‚¬
        isbn (str): ISBN
        publisher_place (str): ì¶œíŒì§€
        date (str): ì¶œíŒì—°ë„

    Returns:
        dict: JSON ì‘ë‹µ ë˜ëŠ” None
    """

    # 1. ì‹¤ì œ ë¸Œë¼ìš°ì € í—¤ë” ì™„ë²½ ëª¨ë°©
    session = requests.Session()

    # Chrome ë¸Œë¼ìš°ì € í—¤ë” ì™„ë²½ ë³µì‚¬
    headers = {
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Encoding": "gzip, deflate, br, zstd",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Cache-Control": "max-age=0",
        "Connection": "keep-alive",
        "DNT": "1",
        "Host": "discover.libraryhub.jisc.ac.uk",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Sec-Fetch-User": "?1",
        "Upgrade-Insecure-Requests": "1",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "sec-ch-ua": '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"',
    }

    session.headers.update(headers)

    # 2. ë¨¼ì € ë©”ì¸ í˜ì´ì§€ì— ë°©ë¬¸í•˜ì—¬ ì¿ í‚¤ì™€ ì„¸ì…˜ ì„¤ì •
    print("ğŸ  ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸í•˜ì—¬ ì„¸ì…˜ ì„¤ì •...")
    try:
        main_response = session.get(
            "https://discover.libraryhub.jisc.ac.uk/", timeout=15
        )
        print(f"âœ… ë©”ì¸ í˜ì´ì§€: {main_response.status_code}")

        # ì¿ í‚¤ í™•ì¸
        cookies = session.cookies.get_dict()
        print(f"ğŸª ë°›ì€ ì¿ í‚¤: {len(cookies)}ê°œ")

    except Exception as e:
        print(f"âš ï¸ ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸ ì‹¤íŒ¨: {e}")
        return None

    # 3. ê²€ìƒ‰ íŒŒë¼ë¯¸í„° êµ¬ì„± (ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ ë°©ì‹ ë”°ë¼í•˜ê¸°)
    params = {}

    # ê²€ìƒ‰ ì¡°ê±´ ì¶”ê°€
    if author:
        params["author"] = author
    if title:
        params["title"] = title
    if subject:
        params["subject"] = subject
    if keyword:
        params["keyword"] = keyword
    if publisher:
        params["publisher"] = publisher
    if isbn:
        params["isbn"] = isbn
    if publisher_place:
        params["publisher-place"] = publisher_place
    if date:
        params["date"] = date

    if not params:
        print("âŒ ê²€ìƒ‰ ì¡°ê±´ì„ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None

    # 4. ì²« ë²ˆì§¸ ì‹œë„: HTML ê²€ìƒ‰ (ì‹¤ì œ ë¸Œë¼ìš°ì € ë™ì‘)
    search_url = "https://discover.libraryhub.jisc.ac.uk/search"
    print(f"\nğŸ” HTML ê²€ìƒ‰ ìš”ì²­: {urlencode(params)}")

    try:
        # Referer í—¤ë” ì¶”ê°€ (ì¤‘ìš”!)
        session.headers.update({"Referer": "https://discover.libraryhub.jisc.ac.uk/"})

        html_response = session.get(search_url, params=params, timeout=20)
        print(f"ğŸ“„ HTML ì‘ë‹µ: {html_response.status_code}")

        if html_response.status_code == 200:
            # HTMLì—ì„œ ê²°ê³¼ ì •ë³´ ì¶”ì¶œ
            html_content = html_response.text

            # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì¶”ì¶œ
            import re

            results_match = re.search(r"Results \d+ - \d+ of (\d+)", html_content)
            total_results = results_match.group(1) if results_match else "ì•Œ ìˆ˜ ì—†ìŒ"

            print(f"ğŸ“Š ì´ ê²€ìƒ‰ ê²°ê³¼: {total_results}ê±´")

            # ì œëª©ë“¤ ì¶”ì¶œ
            title_pattern = r'<h3[^>]*><a[^>]*href="[^"]*">([^<]+)</a></h3>'
            titles = re.findall(title_pattern, html_content)

            if titles:
                print(f"\nğŸ“š ê²€ìƒ‰ëœ ë„ì„œ ì œëª©ë“¤:")
                for i, title in enumerate(titles[:5], 1):
                    # HTML ì—”í‹°í‹° ë””ì½”ë”©
                    import html

                    clean_title = html.unescape(title.strip())
                    print(f"  {i}. {clean_title}")

            # 5. ë‘ ë²ˆì§¸ ì‹œë„: JSON API ìš”ì²­ (HTML ìš”ì²­ í›„)
            print(f"\nğŸ”„ JSON API ì‹œë„...")
            json_params = params.copy()
            json_params["format"] = "json"

            # ì¿ í‚¤ì™€ ì„¸ì…˜ ìœ ì§€í•œ ìƒíƒœì—ì„œ JSON ìš”ì²­
            session.headers.update(
                {
                    "Accept": "application/json, text/plain, */*",
                    "Referer": html_response.url,
                    "X-Requested-With": "XMLHttpRequest",  # AJAX ìš”ì²­ì„ì„ ëª…ì‹œ
                }
            )

            json_response = session.get(search_url, params=json_params, timeout=20)
            print(f"ğŸ“‹ JSON ì‘ë‹µ: {json_response.status_code}")
            print(
                f"ğŸ“‹ Content-Type: {json_response.headers.get('content-type', 'N/A')}"
            )

            if json_response.status_code == 200:
                try:
                    json_data = json_response.json()
                    print(f"ğŸ‰ JSON íŒŒì‹± ì„±ê³µ!")
                    print(f"ğŸ“Š hits: {json_data.get('hits', 0)}")
                    print(f"ğŸ“„ records: {len(json_data.get('records', []))}")

                    # ìƒì„¸ ì •ë³´ ì¶œë ¥
                    records = json_data.get("records", [])
                    if records:
                        print(f"\nğŸ“– ìƒì„¸ ì •ë³´:")
                        for i, record in enumerate(records[:3], 1):
                            print(f"\n{i}. ì œëª©: {record.get('title', 'N/A')}")
                            print(f"   ì €ì: {record.get('author', 'N/A')}")
                            print(f"   ì¶œíŒ: {record.get('publisher', 'N/A')}")
                            print(f"   ì—°ë„: {record.get('date', 'N/A')}")
                            print(f"   ISBN: {record.get('isbn', 'N/A')}")

                    return json_data

                except json.JSONDecodeError as e:
                    print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    print(f"ğŸ“ ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 300ì): {json_response.text[:300]}")
            else:
                print(f"âŒ JSON ìš”ì²­ ì‹¤íŒ¨: {json_response.status_code}")

            # HTMLì€ ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
            return {
                "html_success": True,
                "total_results": total_results,
                "titles": titles,
            }

        else:
            print(f"âŒ HTML ìš”ì²­ë„ ì‹¤íŒ¨: {html_response.status_code}")
            print(f"ğŸ“ ì—ëŸ¬ ë‚´ìš©: {html_response.text[:200]}")
            return None

    except requests.exceptions.RequestException as e:
        print(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
        return None


def search_with_delays(author=None, title=None, **kwargs):
    """
    ì§€ì—° ì‹œê°„ì„ ë‘ê³  ë”ìš± ìì—°ìŠ¤ëŸ¬ìš´ ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
    """
    print("â³ ìì—°ìŠ¤ëŸ¬ìš´ ê²€ìƒ‰ì„ ìœ„í•´ ì ì‹œ ëŒ€ê¸°...")
    time.sleep(2)  # 2ì´ˆ ëŒ€ê¸°

    return search_jisc_like_browser(author=author, title=title, **kwargs)


def test_realistic_search():
    """
    ì‹¤ì œ ë¸Œë¼ìš°ì € ë™ì‘ì„ ì™„ë²½ ëª¨ë°©í•œ í…ŒìŠ¤íŠ¸
    """
    print("=" * 70)
    print("ğŸ¯ ì‹¤ì œ ë¸Œë¼ìš°ì € ë™ì‘ ëª¨ë°© í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    # í…ŒìŠ¤íŠ¸ 1: Sandel + Justice (ì›¹ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸ëœ ì¡°í•©)
    print("\nğŸ” í…ŒìŠ¤íŠ¸ 1: Michael Sandelì˜ Justice ê²€ìƒ‰")
    result1 = search_with_delays(author="sandel", title="justice")

    # í…ŒìŠ¤íŠ¸ 2: ë‹¨ì¼ ì¡°ê±´ ê²€ìƒ‰
    print("\n" + "=" * 50)
    print("ğŸ” í…ŒìŠ¤íŠ¸ 2: ì €ìëª…ë§Œìœ¼ë¡œ ê²€ìƒ‰ (Sandel)")
    result2 = search_with_delays(author="Michael J. Sandel")

    # í…ŒìŠ¤íŠ¸ 3: ISBN ê²€ìƒ‰
    print("\n" + "=" * 50)
    print("ğŸ” í…ŒìŠ¤íŠ¸ 3: ISBN ê²€ìƒ‰")
    result3 = search_with_delays(isbn="9781846142802")

    return result1, result2, result3


def test_advanced_combinations():
    """
    ê³ ê¸‰ ê²€ìƒ‰ ì¡°í•© í…ŒìŠ¤íŠ¸
    """
    print("\n" + "=" * 70)
    print("ğŸ§ª ê³ ê¸‰ ê²€ìƒ‰ ì¡°í•© í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    # ë³µí•© ê²€ìƒ‰
    test_cases = [
        {"title": "liberalism", "author": "sandel", "description": "ì œëª©+ì €ì"},
        {"subject": "political philosophy", "date": "2009", "description": "ì£¼ì œ+ì—°ë„"},
        {"keyword": "justice", "publisher": "harvard", "description": "í‚¤ì›Œë“œ+ì¶œíŒì‚¬"},
        {
            "publisher-place": "cambridge",
            "date": "1990-2020",
            "description": "ì¶œíŒì§€+ì—°ë„ë²”ìœ„",
        },
    ]

    for i, test_case in enumerate(test_cases, 1):
        description = test_case.pop("description")
        print(f"\nğŸ”¬ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ {i}: {description}")
        result = search_with_delays(**test_case)
        time.sleep(3)  # ìš”ì²­ ê°„ ê°„ê²©


if __name__ == "__main__":
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    test_realistic_search()

    # ê³ ê¸‰ í…ŒìŠ¤íŠ¸
    test_advanced_combinations()

    print("\n" + "=" * 70)
    print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ’¡ ì›¹ë¸Œë¼ìš°ì € ë™ì‘ì„ ëª¨ë°©í•˜ì—¬ ë´‡ ì°¨ë‹¨ì„ ìš°íšŒí•˜ë ¤ê³  ì‹œë„í–ˆìŠµë‹ˆë‹¤.")
    print("=" * 70)
