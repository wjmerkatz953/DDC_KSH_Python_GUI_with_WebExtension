# -*- coding: utf-8 -*-
# íŒŒì¼ëª…: Search_Princeton.py
# Version: v2.0.0 - Level 2 ìµœì í™” ì ìš©
# ìˆ˜ì •ì¼ì‹œ: 2025-09-21 KST
# ì„¤ëª…: Princeton University Library API Level 2 ìµœì í™” - httpx HTTP/2, ì¬ì‹œë„ ë¡œì§, DNS ìºì‹±

import requests
import re
from qt_api_clients import translate_text_batch_async, extract_year
from bs4 import BeautifulSoup
import socket
import functools

# ğŸš€ Level 2 ìµœì í™”: httpx ë° HTTP/2 ì§€ì›
try:
    import httpx

    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False

# ğŸš€ MARC í˜ì´ì§€ ìºì‹±ì„ ìœ„í•œ ì „ì—­ ë”•ì…”ë„ˆë¦¬
_marc_cache = {}

# ğŸš€ Level 2 ìµœì í™”: DNS ìºì‹± ì ìš©
socket.getaddrinfo = functools.lru_cache(maxsize=128)(socket.getaddrinfo)

# ğŸš€ Level 2 ìµœì í™”: HTTP í´ë¼ì´ì–¸íŠ¸ ìµœì í™”
_session = None
_httpx_client = None


def _get_optimized_client():
    """ìµœì í™”ëœ HTTP í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _session, _httpx_client

    if HTTPX_AVAILABLE and _httpx_client is None:
        # httpx ì‚¬ìš© (HTTP/2 ì§€ì›)
        _httpx_client = httpx.Client(
            http2=True,
            timeout=httpx.Timeout(5.0),  # ì´ˆê¸° íƒ€ì„ì•„ì›ƒì„ 5ì´ˆë¡œ ì„¤ì •
            limits=httpx.Limits(max_keepalive_connections=20, max_connections=50),
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.5",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
                "Cache-Control": "max-age=0",
            },
        )
        return _httpx_client

    elif _session is None:
        # requests fallback
        _session = requests.Session()

        # Connection Pooling ìµœì í™”
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=20,
            pool_maxsize=50,
            max_retries=0,  # ì¬ì‹œë„ëŠ” ì§ì ‘ êµ¬í˜„
            pool_block=False,
        )
        _session.mount("https://", adapter)
        _session.mount("http://", adapter)

        _session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.5",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
                "Cache-Control": "max-age=0",
            }
        )

    return _session


def _make_request_with_retry(url, params=None, max_retries=3, app_instance=None):
    """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ HTTP ìš”ì²­ - ì ì‘í˜• íƒ€ì„ì•„ì›ƒ"""
    client = _get_optimized_client()

    # ì ì‘í˜• íƒ€ì„ì•„ì›ƒ: ì²« ì‹œë„ëŠ” ë¹ ë¥´ê²Œ, ì¬ì‹œë„í•  ë•ŒëŠ” ì ì§„ì ìœ¼ë¡œ ì¦ê°€
    timeouts = [5, 8, 12]  # 5ì´ˆ â†’ 8ì´ˆ â†’ 12ì´ˆ

    for attempt in range(max_retries):
        current_timeout = timeouts[min(attempt, len(timeouts) - 1)]

        try:
            if HTTPX_AVAILABLE and isinstance(client, httpx.Client):
                # httpx ì‚¬ìš© - ë™ì  íƒ€ì„ì•„ì›ƒ ì„¤ì •
                client.timeout = httpx.Timeout(current_timeout)
                if params:
                    response = client.get(url, params=params)
                else:
                    response = client.get(url)
                response.raise_for_status()

                if app_instance and attempt > 0:
                    app_instance.log_message(
                        f"Princeton API ì„±ê³µ (ì‹œë„ {attempt + 1}, {current_timeout}ì´ˆ)",
                        level="INFO",
                    )
                return response
            else:
                # requests ì‚¬ìš©
                response = client.get(url, params=params, timeout=current_timeout)
                response.raise_for_status()

                if app_instance and attempt > 0:
                    app_instance.log_message(
                        f"Princeton API ì„±ê³µ (ì‹œë„ {attempt + 1}, {current_timeout}ì´ˆ)",
                        level="INFO",
                    )
                return response

        except (requests.Timeout, requests.ConnectionError, Exception) as e:
            # httpx ì˜ˆì™¸ ì²˜ë¦¬
            is_timeout = (
                isinstance(e, requests.Timeout)
                or "timeout" in str(e).lower()
                or "timed out" in str(e).lower()
            )

            if attempt < max_retries - 1:
                if app_instance:
                    if is_timeout:
                        app_instance.log_message(
                            f"Princeton API íƒ€ì„ì•„ì›ƒ ({current_timeout}ì´ˆ) - ì‹œë„ {attempt + 2}/{max_retries} (ë‹¤ìŒ: {timeouts[min(attempt + 1, len(timeouts) - 1)]}ì´ˆ)",
                            level="WARNING",
                        )
                    else:
                        app_instance.log_message(
                            f"Princeton API ì—°ê²° ì˜¤ë¥˜ - ì‹œë„ {attempt + 2}/{max_retries}: {type(e).__name__}",
                            level="WARNING",
                        )
                continue
            else:
                if app_instance:
                    if is_timeout:
                        app_instance.log_message(
                            f"Princeton API ìµœì¢… ì‹¤íŒ¨: ì„œë²„ ì‘ë‹µì´ ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤ (ìµœëŒ€ {current_timeout}ì´ˆ ëŒ€ê¸°)",
                            level="ERROR",
                        )
                    else:
                        app_instance.log_message(
                            f"Princeton API ìµœì¢… ì‹¤íŒ¨: {e}", level="ERROR"
                        )
                raise
        except Exception as e:
            if app_instance:
                app_instance.log_message(
                    f"Princeton API ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", level="ERROR"
                )
            raise

    raise Exception("ì¬ì‹œë„ ë¡œì§ ì˜¤ë¥˜")


def _should_auto_translate(app_instance):
    """ìë™ ë²ˆì—­ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    if hasattr(app_instance, "foreign_auto_translation_var"):
        return app_instance.foreign_auto_translation_var.get()
    if hasattr(app_instance, "db_manager") and app_instance.db_manager:
        value = app_instance.db_manager.get_setting("foreign_auto_translation")
        return value == "true" if value else True
    return True


def _parse_marc_fields_from_html(soup, skip_detailed_fields=False):
    """BeautifulSoup ê°ì²´ì—ì„œ ì£¼ìš” MARC íƒœê·¸ì™€ ë‚´ìš©ì„ í•œë²ˆì— íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    marc_data = {}
    try:
        fields = soup.find_all("div", class_="field")
        for field in fields:
            tag_span = field.find("span", class_="tag")
            if not tag_span:
                continue

            tag = tag_span.get_text(strip=True)

            # ğŸš€ í•„ìˆ˜ ì •ë³´ë§Œ íŒŒì‹± ì˜µì…˜ ì ìš© (245ëŠ” JSONì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë˜ë¯€ë¡œ ì œì™¸)
            if skip_detailed_fields:
                # ìƒì„¸ ì •ë³´ ìŠ¤í‚µ - í•„ìˆ˜ í•„ë“œë§Œ íŒŒì‹± (ëª©ì°¨, ì±…ì†Œê°œ, 245 ì œì™¸)
                if tag not in ["250", "650", "082"]:
                    continue
            else:
                # ì „ì²´ ì •ë³´ íŒŒì‹± (245ëŠ” JSONì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì œì™¸)
                if tag not in ["250", "505", "520", "650", "082"]:
                    continue

            ind1_div = field.find("div", class_="ind1")
            ind2_div = field.find("div", class_="ind2")
            ind1 = (
                ind1_div.get_text(strip=True).replace("\xa0", "#") if ind1_div else "#"
            )
            ind2 = (
                ind2_div.get_text(strip=True).replace("\xa0", "#") if ind2_div else "#"
            )
            # &nbsp; ë¬¸ìë¥¼ #ìœ¼ë¡œ ë³€í™˜
            ind1 = "#" if not ind1 else ind1
            ind2 = "#" if not ind2 else ind2
            indicators = f"{ind1}{ind2}"

            subfields_div = field.find("div", class_="subfields")
            if subfields_div:
                # 650 í•„ë“œì˜ ê²½ìš°, $aì™€ $0ë¥¼ ì¡°í•©
                if tag == "650":
                    sub_a_code = subfields_div.find(
                        "span", class_="sub_code", string=re.compile(r"a\|")
                    )
                    sub_0_code = subfields_div.find(
                        "span", class_="sub_code", string=re.compile(r"0\|")
                    )

                    text_a = (
                        sub_a_code.next_sibling.strip()
                        if sub_a_code and sub_a_code.next_sibling
                        else ""
                    )
                    link_0 = (
                        sub_0_code.next_sibling.strip()
                        if sub_0_code and sub_0_code.next_sibling
                        else ""
                    )

                    full_text = f"{text_a} {link_0}".strip()
                else:  # ë‹¤ë¥¸ í•„ë“œëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¡°í•©
                    text_parts = [
                        part.strip()
                        for part in subfields_div.stripped_strings
                        if not part.endswith("|")
                    ]
                    full_text = " ".join(text_parts)

                if tag not in marc_data:
                    marc_data[tag] = []
                marc_data[tag].append({"text": full_text, "indicators": indicators})
    except Exception:
        return {}
    return marc_data


def _parse_princeton_json_record(record_json, app_instance, skip_detailed_fields=False):
    """Princeton Blacklight APIì˜ JSON ì‘ë‹µ ë° staff_view í˜ì´ì§€ì—ì„œ ì„œì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    attributes = record_json.get("attributes", {})
    links = record_json.get("links", {})

    record = {
        "ì œëª©": attributes.get("title", ""),
        "ì €ì": "",
        "ì¶œíŒì‚¬": "",
        "ì—°ë„": "",
        "ISBN": "",
        "ìƒì„¸ ë§í¬": "",
        "ì£¼ì œì–´_ì›ë¬¸": [],
        "082": "",
        "082 ind": "",
        "ì±…ì†Œê°œ": "",
        "ëª©ì°¨": "",
        "250": "",
        "ì¶œíŒì§€ì—­": "",
    }

    # ê¸°ë³¸ ì •ë³´ íŒŒì‹± (JSON)
    author_display = attributes.get("author_display", {})
    if author_display:
        author_list = author_display.get("attributes", {}).get("value", [])
        record["ì €ì"] = " | ".join(author_list)

    pub_display = attributes.get("pub_created_display", {})
    if pub_display:
        pub_string = pub_display.get("attributes", {}).get("value", [""])[0]
        if pub_string:
            year = extract_year(pub_string)
            if year:
                record["ì—°ë„"] = year
                # ì¶œíŒì§€ì—­ ì¶”ì¶œ: ì½œë¡ (:) ì´ì „ ë¶€ë¶„
                parts_before_year = pub_string.split(year)[0].strip(" :,")
                if ":" in parts_before_year:
                    place_parts = parts_before_year.split(":")
                    record["ì¶œíŒì§€ì—­"] = place_parts[0].strip()  # ì¶œíŒì§€ì—­
                    if len(place_parts) > 1:
                        record["ì¶œíŒì‚¬"] = place_parts[1].strip()  # ì¶œíŒì‚¬
                else:
                    record["ì¶œíŒì‚¬"] = parts_before_year

    isbn_display = attributes.get("isbn_s", {})
    if isbn_display:
        isbn_list = isbn_display.get("attributes", {}).get("value", [])
        record["ISBN"] = " | ".join(isbn_list)

    # LC Call Number (082 í•„ë“œ ëŒ€ì‹  ì‚¬ìš©í•  ìˆ˜ ìˆìŒ)
    lc_call_number = ""
    lc_display = attributes.get("lc_1letter_s", {})
    if lc_display:
        lc_list = lc_display.get("attributes", {}).get("value", [])
        lcc_call_number = " | ".join(lc_list)

    # MARC ìƒì„¸ ì •ë³´ íŒŒì‹± (staff_view í˜ì´ì§€)
    self_link = links.get("self", "")
    if self_link:
        marc_link = f"{self_link}/staff_view"
        record["ìƒì„¸ ë§í¬"] = marc_link

        try:
            # ğŸš€ Level 2 ìµœì í™”: ìºì‹œ í‚¤ì— skip_detailed_fields í¬í•¨
            cache_key = f"{marc_link}_{skip_detailed_fields}"

            if cache_key in _marc_cache:
                parsed_marc = _marc_cache[cache_key]
            else:
                # ğŸš€ Level 2 ìµœì í™”: ê°œì„ ëœ HTTP ìš”ì²­
                response = _make_request_with_retry(
                    marc_link, app_instance=app_instance
                )

                # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ (httpx/requests í˜¸í™˜)
                if hasattr(response, "text"):
                    html_content = response.text
                else:
                    html_content = response.content.decode("utf-8")

                # ğŸš€ BeautifulSoup íŒŒì„œë¥¼ lxmlë¡œ ë³€ê²½ (html.parserë³´ë‹¤ ë¹ ë¦„)
                try:
                    soup = BeautifulSoup(html_content, "lxml")
                except:
                    soup = BeautifulSoup(html_content, "html.parser")

                parsed_marc = _parse_marc_fields_from_html(soup, skip_detailed_fields)

                # ğŸš€ ìºì‹œì— ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ìµœëŒ€ 500ê°œê¹Œì§€ë§Œ)
                if len(_marc_cache) >= 500:
                    # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (FIFO)
                    oldest_key = next(iter(_marc_cache))
                    del _marc_cache[oldest_key]
                _marc_cache[cache_key] = parsed_marc

            # íŒŒì‹±ëœ MARC ë°ì´í„°ë¡œ record ë”•ì…”ë„ˆë¦¬ ìµœì¢… ì™„ì„±
            record["250"] = parsed_marc.get("250", [{}])[0].get("text", "")

            # ğŸš€ ì„ íƒì  íŒŒì‹±: skip_detailed_fieldsê°€ Falseì¼ ë•Œë§Œ ëª©ì°¨, ì±…ì†Œê°œ íŒŒì‹±
            if not skip_detailed_fields:
                record["ëª©ì°¨"] = parsed_marc.get("505", [{}])[0].get("text", "")
                record["ì±…ì†Œê°œ"] = parsed_marc.get("520", [{}])[0].get("text", "")
            else:
                record["ëª©ì°¨"] = ""
                record["ì±…ì†Œê°œ"] = ""

            # ì£¼ì œì–´ ì¶”ì¶œ
            subjects = [field["text"] for field in parsed_marc.get("650", [])]
            if subjects:
                record["ì£¼ì œì–´_ì›ë¬¸"] = subjects

            # DDC 082 í•„ë“œ ì¶”ì¶œ ë° ì •ê·œí™”
            ddc_field = parsed_marc.get("082", [{}])[0]
            if ddc_field.get("text"):
                ddc_raw = ddc_field["text"]
                # ê³µë°± ì „ê¹Œì§€ë§Œ ì¶”ì¶œ í›„ ìŠ¬ë˜ì‹œ ì œê±°
                ddc_before_space = ddc_raw.split()[0] if ddc_raw.split() else ddc_raw
                ddc_clean = ddc_before_space.replace("/", "")
                record["082"] = ddc_clean
                record["082 ind"] = ddc_field["indicators"]
            else:
                record["082"] = ""
                record["082 ind"] = ""

        except Exception as e:
            if app_instance:
                app_instance.log_message(
                    f"ê²½ê³ : Princeton MARC í˜ì´ì§€({marc_link}) íŒŒì‹± ì‹¤íŒ¨: {e}",
                    level="WARNING",
                )
            # ì‹¤íŒ¨ ì‹œ LC Call Numberë¥¼ 082 í•„ë“œë¡œ ì‚¬ìš©
            record["082"] = lcc_call_number

    return record


def search_princeton_library(
    title_query=None,
    author_query=None,
    isbn_query=None,
    year_query=None,
    app_instance=None,
    db_manager=None,
    skip_detailed_fields=False,
):
    """Princeton University Library APIë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not any([title_query, author_query, isbn_query, year_query]):
        if app_instance:
            app_instance.log_message(
                "ê²½ê³ : í”„ë¦°ìŠ¤í„´ ê²€ìƒ‰ì„ ìœ„í•œ ê²€ìƒ‰ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.", level="WARNING"
            )
        return []

    base_url = "https://catalog.princeton.edu/catalog.json"
    params = {}

    if isbn_query:
        params["q"] = isbn_query.replace("-", "").strip()
    else:
        # === ğŸ”§ ì •í™•í•œ Princeton í•„ë“œëª…ìœ¼ë¡œ ìˆ˜ì • ===
        if author_query and not title_query and not year_query:
            # ì €ìë§Œ ê²€ìƒ‰í•  ë•Œ
            params["q"] = author_query
            params["search_field"] = "browse_name"  # Author (browse) ì‚¬ìš©
        elif title_query and author_query:
            # ì œëª© + ì €ì ë³µí•© ê²€ìƒ‰ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€í•˜ë˜ ë” ì •í™•í•œ ì¿¼ë¦¬)
            params["q"] = f'title:"{title_query}" AND author:"{author_query}"'
        elif title_query and not author_query:
            # ì œëª©ë§Œ ê²€ìƒ‰
            params["q"] = f'title:"{title_query}"'
        else:
            # ê¸°íƒ€ ë³µí•© ê²€ìƒ‰ (ë…„ë„ í¬í•¨)
            query_parts = []
            if title_query:
                query_parts.append(f'title:"{title_query}"')
            if author_query:
                query_parts.append(f'author:"{author_query}"')
            if year_query:
                query_parts.append(f'date:"{year_query}"')

            if query_parts:
                params["q"] = " AND ".join(query_parts)
    try:
        # ğŸš€ Level 2 ìµœì í™”: ê°œì„ ëœ API ìš”ì²­ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        if app_instance:
            client_type = "httpx (HTTP/2)" if HTTPX_AVAILABLE else "requests"
            app_instance.log_message(
                f"ì •ë³´: Princeton API ìš”ì²­ ì‹œì‘ ({client_type}): {params}", level="INFO"
            )

        response = _make_request_with_retry(
            base_url, params=params, app_instance=app_instance
        )

        # ì‘ë‹µ ì²˜ë¦¬ (httpx/requests í˜¸í™˜)
        if hasattr(response, "json"):
            response_json = response.json()
        else:
            import json

            response_json = json.loads(response.text)

        records_json = response_json.get("data", [])

        if not records_json:
            if app_instance:
                app_instance.log_message(
                    "ì •ë³´: Princeton ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", level="INFO"
                )
            return []

        # ğŸš€ Level 2 ìµœì í™”: ThreadPoolExecutor ì›Œì»¤ ìˆ˜ ì¶”ê°€ ì¦ê°€ (12 â†’ 15)
        from concurrent.futures import ThreadPoolExecutor, as_completed

        if app_instance:
            app_instance.log_message(
                f"ì •ë³´: Princeton {len(records_json)}ê±´ì˜ ë ˆì½”ë“œë¥¼ ë³‘ë ¬ íŒŒì‹± ì‹œì‘ (ì›Œì»¤ 15ê°œ, {client_type})",
                level="INFO",
            )

        all_results = []

        # ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (15)
        with ThreadPoolExecutor(max_workers=15) as executor:
            future_to_record = {
                executor.submit(
                    _parse_princeton_json_record,
                    record_data,
                    app_instance,
                    skip_detailed_fields,
                ): record_data
                for record_data in records_json
            }

            for future in as_completed(future_to_record):
                try:
                    parsed = future.result()
                    if parsed is not None:
                        all_results.append(parsed)
                except Exception as e:
                    if app_instance:
                        app_instance.log_message(
                            f"ê²½ê³ : Princeton ë ˆì½”ë“œ íŒŒì‹± ì‹¤íŒ¨: {e}", level="WARNING"
                        )

        # ì£¼ì œì–´ ë²ˆì—­ ë¡œì§
        if all_results and _should_auto_translate(app_instance):
            if app_instance:
                app_instance.log_message(
                    "ì •ë³´: Princeton ì£¼ì œì–´ ë²ˆì—­ ì‹œì‘...", level="INFO"
                )

            all_unique_subjects = set(
                s.strip() for r in all_results for s in r.get("ì£¼ì œì–´_ì›ë¬¸", []) if s
            )

            if all_unique_subjects:
                custom_glossary = db_manager.get_all_custom_translations()
                translation_map = translate_text_batch_async(
                    list(all_unique_subjects), app_instance, custom_glossary, db_manager
                )
                for record in all_results:
                    raw_subjects = record.get("ì£¼ì œì–´_ì›ë¬¸", [])
                    record["650 í•„ë“œ"] = " | ".join(raw_subjects)  # ì›ë¬¸ í•„ë“œ
                    translated = [
                        translation_map.get(s.strip(), s.strip()) for s in raw_subjects
                    ]
                    record["650 í•„ë“œ (ë²ˆì—­)"] = " | ".join(translated)  # ë²ˆì—­ í•„ë“œ
                    del record["ì£¼ì œì–´_ì›ë¬¸"]

        elif all_results:
            for record in all_results:
                raw_subjects = record.get("ì£¼ì œì–´_ì›ë¬¸", [])
                record["650 í•„ë“œ"] = " | ".join(raw_subjects)
                record["650 í•„ë“œ (ë²ˆì—­)"] = " | ".join(raw_subjects)
                del record["ì£¼ì œì–´_ì›ë¬¸"]

        if app_instance:
            app_instance.log_message(
                f"ì •ë³´: Princeton ê²€ìƒ‰ ê²°ê³¼ {len(all_results)}ê±´ íŒŒì‹± ì™„ë£Œ.",
                level="INFO",
            )
        return all_results

    except Exception as e:
        if app_instance:
            app_instance.log_message(
                f"ì˜¤ë¥˜: Princeton API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", level="ERROR"
            )
        return []
